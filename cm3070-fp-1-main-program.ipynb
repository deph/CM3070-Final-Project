{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ed1c1ee-e2ec-4b35-b62c-ca9f49991f1c",
   "metadata": {},
   "source": [
    "<div style='text-align: center;'>\n",
    "    <span style='font-size: 30px; font-weight: bold;'>\n",
    "        CM3070 Final Project\n",
    "    </span>\n",
    "</div>\n",
    "<div style='text-align: center;'>\n",
    "    <span style='font-size: 30px; font-weight: bold;'>\n",
    "        Final Report\n",
    "    </span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64d61db-5733-428c-a6b5-ef4332bc16c2",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "673b7004-565a-4928-b068-197cdd9ad31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Libraries\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "import os            # to access operating system functions like file or folder handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab179461-b38b-4252-bdc2-1a011fea0dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Create these folder if they do not exist\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "os.makedirs('saved_models', exist_ok=True)       # for storing features, encoders and trained models\n",
    "os.makedirs('saved_predictions', exist_ok=True)  # for storing predicted probabilities\n",
    "os.makedirs('user_feedback', exist_ok=True)      # for storing user feedback\n",
    "os.makedirs('utils', exist_ok=True)              # for storing custom functions\n",
    "os.makedirs('results', exist_ok=True)            # for storing evaluation results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d09cc79-cfd5-48c1-9bb9-27e414515861",
   "metadata": {},
   "source": [
    "# 2. Dataset Loading, Preprocessing, and Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32019c7a-e844-4452-882a-fb7179239bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Libraries\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "import pandas as pd  # to read CSV files into pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df6f3fd3-9725-4e52-a36f-0b77f03d13f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# FUNCTION - Display dataset summary, size and first few rows of the dataset\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "def display_dataset_info_size_head(df, df_desc):\n",
    "    print(f'\\033[1m{df_desc} summary\\033[0m') \n",
    "    df.info()                                                  # display the dataset summary\n",
    "    print(f'\\n\\033[1m{df_desc} size:\\033[1m', df.shape, '\\n')  # display the number of rows and columns of the dataset\n",
    "    display(df.head(3))                                        # display the first few rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c649bbd-dece-42a8-965d-def4e6104233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# FUNCTION - Display dataset information in a DataFrame format\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "def display_dataframe(headers, data):\n",
    "    df = pd.DataFrame(data, columns=headers)\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa1f0e9-447b-4969-a86f-bfe34daa7185",
   "metadata": {},
   "source": [
    "## 2.1. Dataset 1 - News Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7d44d05-609e-4611-956d-8351555b2294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset 1 summary\u001b[0m\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9900 entries, 0 to 9899\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Text    9900 non-null   object\n",
      " 1   label   9900 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 154.8+ KB\n",
      "\n",
      "\u001b[1mDataset 1 size:\u001b[1m (9900, 2) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Top Trump Surrogate BRUTALLY Stabs Him In The...</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. conservative leader optimistic of common ...</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trump proposes U.S. tax overhaul, stirs concer...</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text label\n",
       "0   Top Trump Surrogate BRUTALLY Stabs Him In The...  Fake\n",
       "1  U.S. conservative leader optimistic of common ...  Real\n",
       "2  Trump proposes U.S. tax overhaul, stirs concer...  Real"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Step 1 - Load the 1st dataset and display the structure, shape and first few rows of the dataframe\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "csv_file = 'datasets/fake_and_real_news.csv'  # set file name of csv file\n",
    "df1 = pd.read_csv(csv_file)                   # read csv file (dataset) into dataframe\n",
    "\n",
    "# Call function - to dislay the dataset summary, size and first few rows of dataset 1\n",
    "df_desc = 'Dataset 1'\n",
    "display_dataset_info_size_head(df1, df_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b107cf6b-816c-47d0-9db4-8f122a050a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset 1 summary\u001b[0m\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9900 entries, 0 to 9899\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    9900 non-null   object\n",
      " 1   label   9900 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 154.8+ KB\n",
      "\n",
      "\u001b[1mDataset 1 size:\u001b[1m (9900, 2) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Top Trump Surrogate BRUTALLY Stabs Him In The...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. conservative leader optimistic of common ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trump proposes U.S. tax overhaul, stirs concer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0   Top Trump Surrogate BRUTALLY Stabs Him In The...      0\n",
       "1  U.S. conservative leader optimistic of common ...      1\n",
       "2  Trump proposes U.S. tax overhaul, stirs concer...      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Step 2 - Rename name of column 'Text' to 'text',\n",
    "#          and convert 'Real' to 1 and 'Fake' to 0 in the label column, \n",
    "#          and display dataset summary\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "# Rename 'Text' to 'text'\n",
    "df1.rename(columns={'Text': 'text'}, inplace=True)\n",
    "\n",
    "# Convert 'Real' to 1 and 'Fake' to 0 in 'label' column\n",
    "df1['label'] = df1['label'].map({'Real': 1, 'Fake': 0})\n",
    "\n",
    "# Call function - to dislay the dataset summary, size and first few rows of dataset 1\n",
    "df_desc = 'Dataset 1'\n",
    "display_dataset_info_size_head(df1, df_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d0251f5-5a25-4887-be03-61e76cb99c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type of news</th>\n",
       "      <th>Label</th>\n",
       "      <th>Number of records</th>\n",
       "      <th>Percentage (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Real</td>\n",
       "      <td>1</td>\n",
       "      <td>4900</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fake</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Type of news  Label Number of records  Percentage (%)\n",
       "0         Real      1              4900              49\n",
       "1         Fake      0              5000              51"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Step 3 - Display number of records and percentages of real and fake news of the dataset\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "headers = ['Type of news', 'Label', 'Number of records', 'Percentage (%)']\n",
    "data = [['Real', 1, str(len(df1[df1['label'] == 1])), round(len(df1[df1['label'] == 1]) / len(df1) * 100)]]\n",
    "data.append (['Fake', 0, str(len(df1[df1['label'] == 0])), round(len(df1[df1['label'] == 0]) / len(df1) * 100)])\n",
    "\n",
    "# Call function - to create and display dataframe\n",
    "display_dataframe(headers, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc42d0b6-3915-4bce-a165-a6839f75eeb1",
   "metadata": {},
   "source": [
    "## 2.2. Dataset 2 - Football Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5c7b9c6-c053-4d82-bee9-ff5fbf4ffba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset 2 (Real news) summary\u001b[0m\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21869 entries, 0 to 21868\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   tweet   21863 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 171.0+ KB\n",
      "\n",
      "\u001b[1mDataset 2 (Real news) size:\u001b[1m (21869, 1) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sun downs technical director: al-ahly respecte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shawky gharib after the tie with enppi: our go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>egyptian sports news today, wednesday 1/25/202...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet\n",
       "0  sun downs technical director: al-ahly respecte...\n",
       "1  shawky gharib after the tie with enppi: our go...\n",
       "2  egyptian sports news today, wednesday 1/25/202..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset 2 (Fake news) summary\u001b[0m\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19999 entries, 0 to 19998\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   tweet   19988 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 156.4+ KB\n",
      "\n",
      "\u001b[1mDataset 2 (Fake news) size:\u001b[1m (19999, 1) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the tongue of his condition, now i saw things ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>by god the great, after i saw the derby of wyd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>believe in god, this zamalek fans are as good ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet\n",
       "0  the tongue of his condition, now i saw things ...\n",
       "1  by god the great, after i saw the derby of wyd...\n",
       "2  believe in god, this zamalek fans are as good ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Step 1 - Load the 2nd datasets (separate real and fake news files), \n",
    "#          and display the structure, shape and first few rows of the dataframe\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "df2_real = pd.read_csv('datasets/real.csv')  # real news\n",
    "df2_fake = pd.read_csv('datasets/fake.csv')  # fake news\n",
    "\n",
    "# For real news dataset\n",
    "# Call function - to dislay the dataset summary, size and first few rows\n",
    "df_desc = 'Dataset 2 (Real news)' \n",
    "display_dataset_info_size_head(df2_real, df_desc)\n",
    "\n",
    "# For fake news dataset\n",
    "# Call function - to dislay the dataset summary, size and first few rows\n",
    "df_desc = 'Dataset 2 (Fake news)'\n",
    "display_dataset_info_size_head(df2_fake, df_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d31dd86-e959-4bf1-a5ec-0a33bfce94e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset 2 (Real news) summary\u001b[0m\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 21863 entries, 0 to 21868\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    21863 non-null  object\n",
      " 1   label   21863 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 512.4+ KB\n",
      "\n",
      "\u001b[1mDataset 2 (Real news) size:\u001b[1m (21863, 2) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sun downs technical director: al-ahly respecte...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shawky gharib after the tie with enppi: our go...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>egyptian sports news today, wednesday 1/25/202...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  sun downs technical director: al-ahly respecte...      1\n",
       "1  shawky gharib after the tie with enppi: our go...      1\n",
       "2  egyptian sports news today, wednesday 1/25/202...      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset 2 (Fake news) summary\u001b[0m\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 19988 entries, 0 to 19998\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    19988 non-null  object\n",
      " 1   label   19988 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 468.5+ KB\n",
      "\n",
      "\u001b[1mDataset 2 (Fake news) size:\u001b[1m (19988, 2) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the tongue of his condition, now i saw things ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>by god the great, after i saw the derby of wyd...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>believe in god, this zamalek fans are as good ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  the tongue of his condition, now i saw things ...      0\n",
       "1  by god the great, after i saw the derby of wyd...      0\n",
       "2  believe in god, this zamalek fans are as good ...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Step 2 - Remove rows with null values, rename the column name to 'text',\n",
    "#          and add a column to each dataset (label = 1 for real news and label = 0 for fake news)\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "# Drop rows with null values\n",
    "df2_real = df2_real.dropna()\n",
    "df2_fake = df2_fake.dropna()\n",
    "\n",
    "# Rename column names\n",
    "df2_real = df2_real.rename(columns={'tweet': 'text'})\n",
    "df2_fake = df2_fake.rename(columns={'tweet': 'text'})\n",
    "\n",
    "# Add a 'label' column to indicate fake (0) or real (1) news\n",
    "df2_real['label'] = 1  # Label for real news\n",
    "df2_fake['label'] = 0  # Label for fake news\n",
    "\n",
    "# For real news dataset\n",
    "# Call function - to dislay the dataset summary, size and first few rows\n",
    "df_desc = 'Dataset 2 (Real news)' \n",
    "display_dataset_info_size_head(df2_real, df_desc)\n",
    "\n",
    "# For fake news dataset\n",
    "# Call function - to dislay the dataset summary, size and first few rows\n",
    "df_desc = 'Dataset 2 (Fake news)'\n",
    "display_dataset_info_size_head(df2_fake, df_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbf5eaf4-5e41-4d0b-9ef8-65f09e940769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>praise be to god, zamalek appeared before al-a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>muhammad marouf is running a match in the prem...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the sudanese team, al-merreikh, ignited the ra...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  praise be to god, zamalek appeared before al-a...      0\n",
       "1  muhammad marouf is running a match in the prem...      1\n",
       "2  the sudanese team, al-merreikh, ignited the ra...      1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Step 3 - Combine the two dataframes into one,\n",
    "#          and shuffle the combined dataframe to jumble the records\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "# Combine the two dataframes into one\n",
    "df2_combined = pd.concat([df2_fake, df2_real], ignore_index=True)\n",
    "\n",
    "# Shuffle the combined dataframe to jumble the records and reset the index after shuffling\n",
    "df2 = df2_combined.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Display the first few records of the shuffled DataFrame\n",
    "df2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b9b0284-caa0-4bdd-8c45-ac0660c7837e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type of news</th>\n",
       "      <th>Label</th>\n",
       "      <th>Number of records</th>\n",
       "      <th>Percentage (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Real</td>\n",
       "      <td>1</td>\n",
       "      <td>21863</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fake</td>\n",
       "      <td>0</td>\n",
       "      <td>19988</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Type of news  Label Number of records  Percentage (%)\n",
       "0         Real      1             21863              52\n",
       "1         Fake      0             19988              48"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Step 4 - Display number of records and percentages of real and fake news of the dataset\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "headers = ['Type of news', 'Label', 'Number of records', 'Percentage (%)']\n",
    "data = [['Real', 1, str(len(df2[df2['label'] == 1])), round(len(df2[df2['label'] == 1]) / len(df2) * 100)]]\n",
    "data.append (['Fake', 0, str(len(df2[df2['label'] == 0])), round(len(df2[df2['label'] == 0]) / len(df2) * 100)])\n",
    "\n",
    "# Call function - to create and display dataframe\n",
    "display_dataframe(headers, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7b46f4-d632-434a-a33e-27e5c3853950",
   "metadata": {},
   "source": [
    "## 2.3. Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e14e4eb3-3ab8-432e-b6af-af57d9f04632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Libraries\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "import re                                 # Python's re module for regular expressions\n",
    "import nltk                               # Nltk library for text processing\n",
    "from nltk.tokenize import word_tokenize   # for word tokenization\n",
    "from nltk.stem import WordNetLemmatizer   # for lemmatization\n",
    "from nltk.corpus import stopwords         # for stop words removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60f556b0-3472-46d5-8cc7-87dc41fad995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Create a copy of datasets before preprocessing to keep the original datasets clean\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "df1_copy = df1.copy()         \n",
    "df2_copy = df2.copy()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3833c982-a7d9-453f-9c98-a387769a389f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# FUNCTION - For word tokenization, lemmatization and stop words removal\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "def token_lemma_stopwords(text):\n",
    "\n",
    "    # Tokenize the text into words\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Lemmatize each word to its base form\n",
    "    lemmatizer = WordNetLemmatizer()                        \n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    \n",
    "    # Remove stop words from the lemmatized tokens\n",
    "    stop_words = set(stopwords.words('english'))            \n",
    "    filtered_tokens = [token for token in lemmatized_tokens if token not in stop_words]\n",
    "    \n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "018dc6a3-b124-4894-aa90-42a9be71fcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# FUNCTION - To clean text (keeping only lowercase letters with only one space between the words\n",
    "#            without leading and trailing spaces), \n",
    "#            and apply word tokenization, lemmatization and stop words removal, \n",
    "#            and join the tokens back into single stringsand an\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "def clean_text(text):\n",
    "\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove non-alphabetical characters (keeping only lowercase letters and spaces)\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "\n",
    "    # Replace multiple spaces with one space and strip leading and trailing spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    # Call function - for word tokenization, lemmatization and stop words removal\n",
    "    text = token_lemma_stopwords(text)\n",
    "\n",
    "    # join tokens back into single strings\n",
    "    text_cleaned = ' '.join(text)  \n",
    "\n",
    "    return text_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5103c76c-e585-412a-9e50-a20d806ca345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset 1\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Top Trump Surrogate BRUTALLY Stabs Him In The...</td>\n",
       "      <td>0</td>\n",
       "      <td>top trump surrogate brutally stab back patheti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. conservative leader optimistic of common ...</td>\n",
       "      <td>1</td>\n",
       "      <td>u conservative leader optimistic common ground...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trump proposes U.S. tax overhaul, stirs concer...</td>\n",
       "      <td>1</td>\n",
       "      <td>trump proposes u tax overhaul stir concern def...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0   Top Trump Surrogate BRUTALLY Stabs Him In The...      0   \n",
       "1  U.S. conservative leader optimistic of common ...      1   \n",
       "2  Trump proposes U.S. tax overhaul, stirs concer...      1   \n",
       "\n",
       "                                        text_cleaned  \n",
       "0  top trump surrogate brutally stab back patheti...  \n",
       "1  u conservative leader optimistic common ground...  \n",
       "2  trump proposes u tax overhaul stir concern def...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset 2\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>praise be to god, zamalek appeared before al-a...</td>\n",
       "      <td>0</td>\n",
       "      <td>praise god zamalek appeared alahly came catch ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>muhammad marouf is running a match in the prem...</td>\n",
       "      <td>1</td>\n",
       "      <td>muhammad marouf running match premier league t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the sudanese team, al-merreikh, ignited the ra...</td>\n",
       "      <td>1</td>\n",
       "      <td>sudanese team almerreikh ignited ranking group...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  praise be to god, zamalek appeared before al-a...      0   \n",
       "1  muhammad marouf is running a match in the prem...      1   \n",
       "2  the sudanese team, al-merreikh, ignited the ra...      1   \n",
       "\n",
       "                                        text_cleaned  \n",
       "0  praise god zamalek appeared alahly came catch ...  \n",
       "1  muhammad marouf running match premier league t...  \n",
       "2  sudanese team almerreikh ignited ranking group...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Clean the 'text' columns for datasets 1 and 2\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "# Call function - to clean the 'text' column and store the cleaned text in a new column 'text_cleaned'\n",
    "df1_copy['text_cleaned'] = df1_copy['text'].apply(clean_text)\n",
    "df2_copy['text_cleaned'] = df2_copy['text'].apply(clean_text)\n",
    "\n",
    "# Display the first few records of the cleaned datasets\n",
    "print(\"\\033[1mDataset 1\\033[0m\")\n",
    "display(df1_copy.head(3))          # dataset 1\n",
    "\n",
    "print(\"\\033[1mDataset 2\\033[0m\")   \n",
    "display(df2_copy.head(3))          # dataset 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1473a979-c2f8-4286-b158-737c8f7078f1",
   "metadata": {},
   "source": [
    "## 2.4. Dataset Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a748e439-c6f0-42e3-8dbe-2e8dff0bb840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Libraries\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "from sklearn.model_selection import train_test_split   # for splitting 1 dataset into 2 sets\n",
    "from sklearn.utils import shuffle                      # for shuffling texts and labels together to jumble the records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50d863ff-02d2-4d51-972e-74b254eb5e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Retrieve the cleaned texts and labels from datasets 1 and 2\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "# For dataset 1\n",
    "X1 = df1_copy['text_cleaned']       \n",
    "y1 = df1_copy['label']     \n",
    "\n",
    "# For dataset 2\n",
    "X2 = df2_copy['text_cleaned']       \n",
    "y2 = df2_copy['label']     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dad1a31a-c473-4c26-af1c-0783472e4bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>X train (text)</th>\n",
       "      <th>y train (label)</th>\n",
       "      <th>train %</th>\n",
       "      <th>X val (text)</th>\n",
       "      <th>y val (label)</th>\n",
       "      <th>validation %</th>\n",
       "      <th>X test (text)</th>\n",
       "      <th>y test (label)</th>\n",
       "      <th>test %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dataset 1</td>\n",
       "      <td>(7920,)</td>\n",
       "      <td>(7920,)</td>\n",
       "      <td>80</td>\n",
       "      <td>(990,)</td>\n",
       "      <td>(990,)</td>\n",
       "      <td>10</td>\n",
       "      <td>(990,)</td>\n",
       "      <td>(990,)</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dataset 2</td>\n",
       "      <td>(33480,)</td>\n",
       "      <td>(33480,)</td>\n",
       "      <td>80</td>\n",
       "      <td>(4185,)</td>\n",
       "      <td>(4185,)</td>\n",
       "      <td>10</td>\n",
       "      <td>(4186,)</td>\n",
       "      <td>(4186,)</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dataset X train (text) y train (label)  train % X val (text)  \\\n",
       "0  Dataset 1        (7920,)         (7920,)       80       (990,)   \n",
       "1  Dataset 2       (33480,)        (33480,)       80      (4185,)   \n",
       "\n",
       "  y val (label)  validation % X test (text) y test (label)  test %  \n",
       "0        (990,)            10        (990,)         (990,)      10  \n",
       "1       (4185,)            10       (4186,)        (4186,)      10  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Split datasets 1 and 2, each into 80% training, 10% validation and 10% test sets,\n",
    "# and display the shapes of the sets\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "# X_train X_train --> texts of training set\n",
    "# X_val   X_val   --> texts of validation set\n",
    "# X_test  X_test  --> texts of test set\n",
    "# y_train y_train --> labels 1 (Real) and 0 (Fake) of training set\n",
    "# X_val   X_val   --> labels 1 (Real) and 0 (Fake) of validation set\n",
    "# y_test  y_test  --> labels 1 (Real) and 0 (Fake) of test set\n",
    "\n",
    "# Split datasets into train and temp sets for datasets 1 and 2\n",
    "X1_train, X1_temp, y1_train, y1_temp = train_test_split(X1, y1, test_size=0.2, random_state=42)\n",
    "X2_train, X2_temp, y2_train, y2_temp = train_test_split(X2, y2, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split temp datasets into validation and test sets for datasets 1 and 2\n",
    "X1_val, X1_test, y1_val, y1_test = train_test_split(X1_temp, y1_temp, test_size=0.5, random_state=42)\n",
    "X2_val, X2_test, y2_val, y2_test = train_test_split(X2_temp, y2_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Define dataset headers for training, validation, and test sets for datasets 1 and 2\n",
    "headers = ['Dataset', 'X train (text)', 'y train (label)', 'train %', \n",
    "                      'X val (text)', 'y val (label)', 'validation %',\n",
    "                      'X test (text)', 'y test (label)', 'test %']\n",
    "\n",
    "# Store dataset shapes for training, validation, and test sets for datasets 1\n",
    "data = [['Dataset 1', X1_train.shape, y1_train.shape, round(len(X1_train) / len(X1) * 100),\n",
    "                      X1_val.shape, y1_val.shape, round(len(X1_val) / len(X1) * 100),\n",
    "                      X1_test.shape, y1_test.shape, round(len(X1_test) / len(X1) * 100)]]\n",
    "\n",
    "# Store dataset shapes for training, validation, and test sets for dataset 2\n",
    "data.append (['Dataset 2', X2_train.shape, y2_train.shape, round(len(X2_train) / len(X2) * 100),\n",
    "                           X2_val.shape, y2_val.shape, round(len(X2_val) / len(X2) * 100),\n",
    "                           X2_test.shape, y2_test.shape, round(len(X2_test) / len(X2) * 100)])\n",
    "\n",
    "# Call function - to display shapes of training, validation and test sets for datasets 1 and 2\n",
    "display_dataframe(headers, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9a18e9e-7fa7-41fd-8fad-1b06be987389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTraining texts\u001b[0m\n",
      "0    way problem fan zamalek turki alsheikh fact cl...\n",
      "1    course real coach team know khebari better nas...\n",
      "2    alahly defeated zamalek african final var alah...\n",
      "Name: text_cleaned, dtype: object\n",
      "\n",
      "\u001b[1mTraining labels\u001b[0m\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "Name: label, dtype: int64\n",
      "\n",
      "\u001b[1mValidation texts\u001b[0m\n",
      "0                      demand continuation league haha\n",
      "1    haha next week boatman got fat thought sukkary...\n",
      "2    manchester except swissdad barcelona real beti...\n",
      "Name: text_cleaned, dtype: object\n",
      "\n",
      "\u001b[1mValidation labels\u001b[0m\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Combine training and validation sets of datasets 1 and 2 together \n",
    "# --------------------------------------------------------------------------------------------------\n",
    "# Combine texts of both training sets together by stacking rows\n",
    "X_train = pd.concat([X1_train, X2_train], ignore_index=True)\n",
    "y_train = pd.concat([y1_train, y2_train], ignore_index=True)\n",
    "\n",
    "# Combine labels of both validation sets together by stacking rows\n",
    "X_val = pd.concat([X1_val, X2_val], ignore_index=True)\n",
    "y_val = pd.concat([y1_val, y2_val], ignore_index=True)\n",
    "\n",
    "# Shuffle the combined texts and labels together to jumble the records\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=42)\n",
    "X_val, y_val = shuffle(X_val, y_val, random_state=42)\n",
    "\n",
    "# Reset index\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "X_val = X_val.reset_index(drop=True)\n",
    "y_val = y_val.reset_index(drop=True)\n",
    "\n",
    "# Display first few rows of texts and labels of training and validation sets\n",
    "print(\"\\033[1mTraining texts\\033[0m\")\n",
    "print(X_train.head(3))\n",
    "print()\n",
    "print(\"\\033[1mTraining labels\\033[0m\")\n",
    "print(y_train.head(3))\n",
    "print()\n",
    "print(\"\\033[1mValidation texts\\033[0m\")\n",
    "print(X_val.head(3))\n",
    "print()\n",
    "print(\"\\033[1mValidation labels\\033[0m\")\n",
    "print(y_val.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "505c5544-8820-4805-9506-5bfad814b2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset 1 Test texts\u001b[0m\n",
      "0    trump explodes obama drop devastating truth bo...\n",
      "1    trump explained u position thaad xi south kore...\n",
      "2    house widens ethic probe include farenthold ca...\n",
      "Name: text_cleaned, dtype: object\n",
      "\n",
      "\u001b[1mDataset 1 Test labels\u001b[0m\n",
      "0    0\n",
      "1    1\n",
      "2    1\n",
      "Name: label, dtype: int64\n",
      "\n",
      "\u001b[1mDataset 2 Test texts\u001b[0m\n",
      "0    mokhtar mokhtar marvel queirozs choice prelimi...\n",
      "1    ahmed alfadly egyptian ambassador south africa...\n",
      "2    hahahahahahahahahahahahahahahahahahahahahahaha...\n",
      "Name: text_cleaned, dtype: object\n",
      "\n",
      "\u001b[1mDataset 2 Test labels\u001b[0m\n",
      "0    1\n",
      "1    1\n",
      "2    0\n",
      "Name: label, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Rename test sets names to follow same convention as training and validation sets\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "# Rename for test set 1\n",
    "X_test_1 = X1_test\n",
    "y_test_1 = y1_test\n",
    "\n",
    "# Rename for test set 2\n",
    "X_test_2 = X2_test\n",
    "y_test_2 = y2_test\n",
    "\n",
    "# Reset index for test set 1\n",
    "X_test_1 = X_test_1.reset_index(drop=True)\n",
    "y_test_1 = y_test_1.reset_index(drop=True)\n",
    "\n",
    "# Reset index for test set 2\n",
    "X_test_2 = X_test_2.reset_index(drop=True)\n",
    "y_test_2 = y_test_2.reset_index(drop=True)\n",
    "\n",
    "# Display first few rows of texts and labels of test sets 1 and 2 \n",
    "print(\"\\033[1mDataset 1 Test texts\\033[0m\")\n",
    "print(X_test_1.head(3))\n",
    "print()\n",
    "print(\"\\033[1mDataset 1 Test labels\\033[0m\")\n",
    "print(y_test_1.head(3))\n",
    "print()\n",
    "print(\"\\033[1mDataset 2 Test texts\\033[0m\")\n",
    "print(X_test_2.head(3))\n",
    "print()\n",
    "print(\"\\033[1mDataset 2 Test labels\\033[0m\")\n",
    "print(y_test_2.head(3))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ed2bef-5fc1-40ec-8b86-4865ad9ac80e",
   "metadata": {},
   "source": [
    "## 2.5. Save Dataset Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2badfcf5-0b33-43ff-8d5b-f380bbc0281e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Libraries\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "import joblib   # for saving data, features, models and evaluation results for retrievals across kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c191115a-a89b-4231-b83d-456b04012615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['datasets/y_test_2.pkl']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Save training, validation and test sets for retrievals across kernels\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "# Save data of training, validation and test setes\n",
    "joblib.dump(X_train, 'datasets/X_train.pkl')\n",
    "joblib.dump(X_val, 'datasets/X_val.pkl')\n",
    "joblib.dump(X_test_1, 'datasets/X_test_1.pkl')\n",
    "joblib.dump(X_test_2, 'datasets/X_test_2.pkl')\n",
    "\n",
    "# Save labels of training, validation and test sets\n",
    "joblib.dump(y_train, 'datasets/y_train.pkl')\n",
    "joblib.dump(y_val, 'datasets/y_val.pkl')\n",
    "joblib.dump(y_test_1, 'datasets/y_test_1.pkl')\n",
    "joblib.dump(y_test_2, 'datasets/y_test_2.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70c422a-88e9-4a4c-93cb-d6aeebaca83e",
   "metadata": {},
   "source": [
    "# 3. Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccc6d27-006b-415d-bbf9-4f9e5318ad5a",
   "metadata": {},
   "source": [
    "## 3.1.  Utility Function for Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2395a07b-d164-49bc-86fc-c75fe3bb7c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting utils/evaluate_model_performance.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile utils/evaluate_model_performance.py\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "# FUNCTION - Metrics to evaluate the effectiveness of the trained models,\n",
    "#            and save this function into the 'utils' folder as a Python file\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "import pandas as pd            # to read CSV files into pandas dataframe\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,            # overall correctness\n",
    "    precision_score,           # correct positives / predicted positives\n",
    "    recall_score,              # correct positives / actual positives\n",
    "    f1_score,                  # balance between precision and recall\n",
    "    classification_report      # detailed per-class performance\n",
    ")\n",
    "\n",
    "def evaluate_model_performance(model_num, model_name, model_type, model_desc, actual_labels, predicted_labels):\n",
    "\n",
    "    print(f'\\033[1m\\n{model_desc}:\\n\\033[0m')\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(actual_labels, predicted_labels)\n",
    "    precision = precision_score(actual_labels, predicted_labels)\n",
    "    recall = recall_score(actual_labels, predicted_labels)\n",
    "    f1 = f1_score(actual_labels, predicted_labels)\n",
    "\n",
    "    # Create a single-row DataFrame with metric names as columns\n",
    "    results_df = pd.DataFrame({\n",
    "        'Model': [model_num],\n",
    "        'Model name': [model_name],\n",
    "        'Accuracy': [accuracy],\n",
    "        'Precision': [precision],\n",
    "        'Recall': [recall],\n",
    "        'F1 Score': [f1],\n",
    "        'Model type': [model_type]\n",
    "    })\n",
    "\n",
    "    # Style: bold 'Accuracy' column and format all values to 2 decimal places\n",
    "    styled_df = results_df.style \\\n",
    "        .map(lambda val: 'font-weight: bold', subset=['Accuracy']) \\\n",
    "        .format(precision=2)\n",
    "\n",
    "    # Display the full table with bolded Accuracy column\n",
    "    display(styled_df)\n",
    "    \n",
    "    # Classification Report\n",
    "    class_report = classification_report(actual_labels, predicted_labels, target_names=['Real', 'Fake'])\n",
    "    print(f\"Classification Report:\\n{class_report}\")\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a023a497-2851-4b13-a560-3ce9ac4111f3",
   "metadata": {},
   "source": [
    "## 3.2. Utility Function for Storing Evaluation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33afc8e5-6a38-4c62-9bd6-cc12aa3f5e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting utils/store_evaluation_results.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile utils/store_evaluation_results.py\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "# FUNCTION - Store evaluation results for validation and test phases\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "import joblib   # for saving data, features, models and evaluation results for retrievals across kernels\n",
    "def store_evaluation_results(phase, test_set, first_model, model_num, result):\n",
    "\n",
    "    # Set the location of the file path depending on validation (value 1), test phase (value 2) and test sets (1 or 2)\n",
    "    if phase == 1:\n",
    "        file_path = 'results/all_model_results_val.pkl'\n",
    "    else:\n",
    "        if test_set == 1:\n",
    "            file_path = 'results/all_model_results_test_1.pkl'\n",
    "        else:\n",
    "            file_path = 'results/all_model_results_test_2.pkl'\n",
    "\n",
    "    # List to store evaluation results for all models\n",
    "    # If it is the first model for that phase or test set, intialise list\n",
    "    # Else (subsequent runs), retrieve the stored list\n",
    "    if first_model == True:\n",
    "        all_model_results = []\n",
    "    else:\n",
    "        all_model_results = joblib.load(file_path)\n",
    "        \n",
    "    # append evaluation results for current model to \n",
    "    all_model_results.append(result)\n",
    "\n",
    "    # Save the results\n",
    "    joblib.dump(all_model_results, file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5864147d-0154-4fe1-b805-d8bdd7a35334",
   "metadata": {},
   "source": [
    "# 4. Feature Engineering and Traditional & Deep Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "017fabe4-91a9-4367-b2e8-ab4610146ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Libraries\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "import joblib   # for saving models for future use and retrieval of models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f2ec34-86cf-464c-b865-b15251b2200a",
   "metadata": {},
   "source": [
    "## 4.1. TF-IDF Vectorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "173f60fc-8208-4fa0-b822-ee776d5296dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Libraries\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "# TFIDF for text vectorisation (weight words by importance)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2b1b4ea9-56f8-49c3-ac51-6ac40d60951f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['datasets/X_test_2_tfidf.pkl']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Convert text data to numerical features using TFIDF Vectoriser, representing text as word\n",
    "# occurrence counts\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "# Define model parameters\n",
    "NUM_WORDS = 10000\n",
    "\n",
    "# Transforms text into TF-IDF features, keeping only top max_features words and removing stopwords\n",
    "vectorizer_tfidf = TfidfVectorizer(max_features=NUM_WORDS, stop_words='english')\n",
    "\n",
    "# Learn vocabulary from training data\n",
    "vectorizer_tfidf.fit(X_train)\n",
    "\n",
    "# Save the TF-IDF vectorizer for future use\n",
    "joblib.dump(vectorizer_tfidf, \"saved_models/vectorizer_tfidf.pkl\")\n",
    "\n",
    "# Transform datasets using the same vocabulary\n",
    "X_train_tfidf = vectorizer_tfidf.transform(X_train)\n",
    "X_val_tfidf = vectorizer_tfidf.transform(X_val)\n",
    "X_test_1_tfidf = vectorizer_tfidf.transform(X_test_1)\n",
    "X_test_2_tfidf = vectorizer_tfidf.transform(X_test_2)\n",
    "\n",
    "# Save TF-IDF transformed datasets\n",
    "joblib.dump(X_train_tfidf, 'datasets/X_train_tfidf.pkl')\n",
    "joblib.dump(X_val_tfidf, 'datasets/X_val_tfidf.pkl')\n",
    "joblib.dump(X_test_1_tfidf, 'datasets/X_test_1_tfidf.pkl')\n",
    "joblib.dump(X_test_2_tfidf, 'datasets/X_test_2_tfidf.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f0b64f-f332-46ed-b7aa-625e8b92fbb1",
   "metadata": {},
   "source": [
    "## 4.2. Tokenisation and Padding for CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "37269143-9c1f-4131-b9bc-f77dd1f7ae52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 13:49:36.354570: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743313776.369581   10807 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743313776.373573   10807 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743313776.384188   10807 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743313776.384208   10807 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743313776.384210   10807 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743313776.384211   10807 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-30 13:49:36.388010: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Libraries\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer           # Converts text to integer sequences\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences   # Pads sequences to equal length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "87adc970-5a90-4479-bfe2-a5293c2db9b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['datasets/X_test_2_padded.pkl']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Tokenise text, convert it to sequences, and pad them for uniform input in CNN model\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "# Define model parameters\n",
    "NUM_WORDS = 10000\n",
    "MAX_LEN = 500\n",
    "\n",
    "# Tokenizer to learn the vocabulary\n",
    "tokenizer_cnn = Tokenizer(num_words=NUM_WORDS, oov_token=\"<OOV>\")\n",
    "tokenizer_cnn.fit_on_texts(X_train)\n",
    "\n",
    "# Save the trained tokenizer\n",
    "joblib.dump(tokenizer_cnn, \"saved_models/tokenizer_cnn.pkl\")\n",
    "\n",
    "# Convert text into sequences\n",
    "X_train_seq = tokenizer_cnn.texts_to_sequences(X_train)\n",
    "X_val_seq = tokenizer_cnn.texts_to_sequences(X_val)\n",
    "X_test_1_seq = tokenizer_cnn.texts_to_sequences(X_test_1)\n",
    "X_test_2_seq = tokenizer_cnn.texts_to_sequences(X_test_2)\n",
    "\n",
    "# Pad sequences to ensure equal length\n",
    "X_train_padded = pad_sequences(X_train_seq, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "X_val_padded = pad_sequences(X_val_seq, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "X_test_1_padded = pad_sequences(X_test_1_seq, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "X_test_2_padded = pad_sequences(X_test_2_seq, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "\n",
    "# Save the padded sequences\n",
    "joblib.dump(X_train_padded, 'datasets/X_train_padded.pkl')\n",
    "joblib.dump(X_val_padded, 'datasets/X_val_padded.pkl')\n",
    "joblib.dump(X_test_1_padded, 'datasets/X_test_1_padded.pkl')\n",
    "joblib.dump(X_test_2_padded, 'datasets/X_test_2_padded.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc82c66-718e-447e-8e1a-76cd2470df7b",
   "metadata": {},
   "source": [
    "## 4.3. Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "42839957-8ea6-43ab-a6a4-9cb1246aefdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Libraries\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "from sklearn.preprocessing import LabelEncoder   # for encoding categorical labels into numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d2cbeee8-bbdc-40a1-9fc6-d00e57c6f942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['datasets/y_test_2_encoded.pkl']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Encode categorical labels into numerical values\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "# Initialise label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit encoder to training labels\n",
    "label_encoder.fit(y_train)\n",
    "\n",
    "# Save the label encoder\n",
    "joblib.dump(label_encoder, 'saved_models/label_encoder.pkl')\n",
    "\n",
    "# Encode training, validation and tests labels\n",
    "y_train_encoded = label_encoder.transform(y_train)\n",
    "y_val_encoded = label_encoder.transform(y_val)\n",
    "y_test_1_encoded = label_encoder.transform(y_test_1)\n",
    "y_test_2_encoded = label_encoder.transform(y_test_2)\n",
    "\n",
    "# Save encoded labels separately\n",
    "joblib.dump(y_train_encoded, 'datasets/y_train_encoded.pkl')\n",
    "joblib.dump(y_val_encoded, 'datasets/y_val_encoded.pkl')\n",
    "joblib.dump(y_test_1_encoded, 'datasets/y_test_1_encoded.pkl')\n",
    "joblib.dump(y_test_2_encoded, 'datasets/y_test_2_encoded.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f154beac-f6a7-472d-afa9-37cb8c261c3c",
   "metadata": {},
   "source": [
    "## 4.4 Model 1: Naive Bayes (Baseline Model) with TF-IDF Vectoriser - Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "73d4bc48-ea11-4811-84d4-6d923cc99347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Libraries\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "from sklearn.naive_bayes import MultinomialNB                             # Multinomial Naive Bayes model\n",
    "from importlib import reload                                              # to reload updated Python modules\n",
    "import utils.evaluate_model_performance                                   # import custom function (needed for reload)\n",
    "reload(utils.evaluate_model_performance)                                  # reload to reflect any latest changes in file\n",
    "from utils.evaluate_model_performance import evaluate_model_performance   # custom function to evaluate models\n",
    "import utils.store_evaluation_results                                     # import custom function (needed for reload)\n",
    "reload(utils.store_evaluation_results)                                    # reload to reflect any latest changes in file\n",
    "from utils.store_evaluation_results import store_evaluation_results       # custom function to store evaluation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5bbdea01-7188-48cf-ae8d-f7867635d663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['saved_models/model_nb.pkl']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Step 1 - Train and save a Multinomial Naive Bayes model using TF-IDF features\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "# Initialise the Multinomial NB models\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "# Train the model\n",
    "nb_model.fit(X_train_tfidf.toarray(), y_train)\n",
    "\n",
    "# Save the naive bayes model and the TF-IDF vectorizer for future use.\n",
    "joblib.dump(nb_model, \"saved_models/model_nb.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ea4ce3bb-d8e6-4859-9e76-dc87d7f23572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "Model 1: Naive Bayes (Baseline model) using TF-IDF Vectoriser\n",
      "Validation Set:\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_95a47_row0_col2 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_95a47\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_95a47_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_95a47_level0_col1\" class=\"col_heading level0 col1\" >Model name</th>\n",
       "      <th id=\"T_95a47_level0_col2\" class=\"col_heading level0 col2\" >Accuracy</th>\n",
       "      <th id=\"T_95a47_level0_col3\" class=\"col_heading level0 col3\" >Precision</th>\n",
       "      <th id=\"T_95a47_level0_col4\" class=\"col_heading level0 col4\" >Recall</th>\n",
       "      <th id=\"T_95a47_level0_col5\" class=\"col_heading level0 col5\" >F1 Score</th>\n",
       "      <th id=\"T_95a47_level0_col6\" class=\"col_heading level0 col6\" >Model type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_95a47_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_95a47_row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "      <td id=\"T_95a47_row0_col1\" class=\"data row0 col1\" >Naive Bayes</td>\n",
       "      <td id=\"T_95a47_row0_col2\" class=\"data row0 col2\" >0.93</td>\n",
       "      <td id=\"T_95a47_row0_col3\" class=\"data row0 col3\" >0.94</td>\n",
       "      <td id=\"T_95a47_row0_col4\" class=\"data row0 col4\" >0.93</td>\n",
       "      <td id=\"T_95a47_row0_col5\" class=\"data row0 col5\" >0.94</td>\n",
       "      <td id=\"T_95a47_row0_col6\" class=\"data row0 col6\" >Baseline</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x75aeb3dba7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Real       0.93      0.93      0.93      2479\n",
      "        Fake       0.94      0.93      0.94      2696\n",
      "\n",
      "    accuracy                           0.93      5175\n",
      "   macro avg       0.93      0.93      0.93      5175\n",
      "weighted avg       0.93      0.93      0.93      5175\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Step 2 - Generate predictions and evaluate the Naive Bayes model on the validation set,\n",
    "#          and save predictions for stacking (ensemble) model later.\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "# Predict class labels for the validation set\n",
    "y_pred_val_nb = nb_model.predict(X_val_tfidf.toarray())\n",
    "\n",
    "# Predict class probabilities for the validation set\n",
    "y_pred_proba_val_nb = nb_model.predict_proba(X_val_tfidf.toarray())\n",
    "\n",
    "# Save predicted probabilities for ensemble stacking\n",
    "joblib.dump(y_pred_proba_val_nb, \"saved_predictions/y_pred_proba_val_nb.pkl\")\n",
    "\n",
    "# Call function - to evaluate the effectiveness of the model\n",
    "model_num = 1\n",
    "model_name = 'Naive Bayes'\n",
    "model_type = 'Baseline'\n",
    "model_desc = f'Model {model_num}: {model_name} ({model_type} model) using TF-IDF Vectoriser\\nValidation Set'\n",
    "result     = evaluate_model_performance(model_num, model_name, model_type, model_desc, y_val, y_pred_val_nb)\n",
    "\n",
    "# Call function - to store validation results\n",
    "phase = 1                  # 1 for validation phase / 2 for testing phase\n",
    "test_set = 0               # test set 1 or 2 for testing phase\n",
    "first_model = True         # True for first model for that phase / False for subsequent model for the same phase\n",
    "store_evaluation_results(phase, test_set, first_model, model_num, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a2818d-43dd-414d-b159-6209feb187f8",
   "metadata": {},
   "source": [
    "## 4.5. Model 2: Logistic Regression (Traditional Machine Learning) with TF-IDF Vectoriser - Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "998c260b-ab8a-43f7-8bb3-857a006878eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Libraries\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "from sklearn.linear_model import LogisticRegression   # Statistical model - Logistic Regression\n",
    "from sklearn.model_selection import GridSearchCV      # Tunes hyperparameters via cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "79475848-12db-4747-995b-2cdef4e47d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Best parameters found: {'C': 10, 'penalty': 'l2'}\n",
      "Best cross-validation accuracy: 0.99138978054308\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['saved_models/model_lr_best.pkl']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Step 1 - Perform hyperparameter tuning for Logistic Regression using GridSearchCV, \n",
    "#          and select the best model, and save it\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "# Define a parameter grid for regularization strength 'C'\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l2']              # L2 regularization\n",
    "}\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "model_lr = LogisticRegression(max_iter=1000, solver='lbfgs', class_weight='balanced')\n",
    "\n",
    "# Set up GridSearchCV with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(model_lr, param_grid, cv=5, scoring='roc_auc', n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print(\"Best parameters found:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation accuracy:\", grid_search.best_score_)\n",
    "\n",
    "# Use the best model from grid search\n",
    "model_lr_best = grid_search.best_estimator_\n",
    "\n",
    "# Save the naive bayes model and the TF-IDF vectorizer for future use.\n",
    "joblib.dump(model_lr_best, \"saved_models/model_lr_best.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "033e42b3-2259-4b97-89ed-996ff2cc2224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "Model 2: Logistic Regression (Traditional Machine Learning model) using TF-IDF Vectoriser with Regularization\n",
      "Validation Set:\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_04cd5_row0_col2 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_04cd5\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_04cd5_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_04cd5_level0_col1\" class=\"col_heading level0 col1\" >Model name</th>\n",
       "      <th id=\"T_04cd5_level0_col2\" class=\"col_heading level0 col2\" >Accuracy</th>\n",
       "      <th id=\"T_04cd5_level0_col3\" class=\"col_heading level0 col3\" >Precision</th>\n",
       "      <th id=\"T_04cd5_level0_col4\" class=\"col_heading level0 col4\" >Recall</th>\n",
       "      <th id=\"T_04cd5_level0_col5\" class=\"col_heading level0 col5\" >F1 Score</th>\n",
       "      <th id=\"T_04cd5_level0_col6\" class=\"col_heading level0 col6\" >Model type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_04cd5_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_04cd5_row0_col0\" class=\"data row0 col0\" >2</td>\n",
       "      <td id=\"T_04cd5_row0_col1\" class=\"data row0 col1\" >Logistic Regression</td>\n",
       "      <td id=\"T_04cd5_row0_col2\" class=\"data row0 col2\" >0.96</td>\n",
       "      <td id=\"T_04cd5_row0_col3\" class=\"data row0 col3\" >0.96</td>\n",
       "      <td id=\"T_04cd5_row0_col4\" class=\"data row0 col4\" >0.96</td>\n",
       "      <td id=\"T_04cd5_row0_col5\" class=\"data row0 col5\" >0.96</td>\n",
       "      <td id=\"T_04cd5_row0_col6\" class=\"data row0 col6\" >Traditional Machine Learning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x75aeb3dba5e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Real       0.96      0.96      0.96      2479\n",
      "        Fake       0.96      0.96      0.96      2696\n",
      "\n",
      "    accuracy                           0.96      5175\n",
      "   macro avg       0.96      0.96      0.96      5175\n",
      "weighted avg       0.96      0.96      0.96      5175\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Step 2 - Generate predictions and evaluate the Logistic Regression model on the validation set,\n",
    "#          and save predictions for stacking (ensemble) model later.\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "# Predict class labels for the validation set\n",
    "y_pred_val_lr = model_lr_best.predict(X_val_tfidf)\n",
    "\n",
    "# Predict class probabilities for the validation set\n",
    "y_pred_proba_val_lr = model_lr_best.predict_proba(X_val_tfidf)\n",
    "\n",
    "# Save predicted probabilities for ensemble stacking\n",
    "joblib.dump(y_pred_proba_val_lr, \"saved_predictions/y_pred_proba_val_lr.pkl\")\n",
    "\n",
    "# Call function - to evaluate the effectiveness of the model\n",
    "model_num = 2\n",
    "model_name = 'Logistic Regression'\n",
    "model_type = 'Traditional Machine Learning'\n",
    "model_desc = f'Model {model_num}: {model_name} ({model_type} model) using TF-IDF Vectoriser with Regularization\\nValidation Set'\n",
    "result     = evaluate_model_performance(model_num, model_name, model_type, model_desc, y_val, y_pred_val_lr)\n",
    "\n",
    "# Call function - to store validation results\n",
    "phase = 1                  # 1 for validation phase / 2 for testing phase\n",
    "test_set = 0               # test set 1 or 2 for testing phase\n",
    "first_model = False        # True for first model for that phase / False for subsequent model for the same phase\n",
    "store_evaluation_results(phase, test_set, first_model, model_num, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0f620d-07f0-4a90-8b5a-9e0062f50f5a",
   "metadata": {},
   "source": [
    "## 4.6. Model 3: CNN (Deep Learning Model) - Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2dfc56fc-9ed8-4577-8968-cedc027cde47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Libraries\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "from tensorflow.keras.models import Sequential                                                            # Build CNN model\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dense, Dropout, Embedding, GlobalMaxPooling1D   # CNN layers\n",
    "import numpy as np                                                                                        # for numerical operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0bf0e084-5350-47e8-83ff-0ca2f81e8f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Step 1 - Load the preprocessed input data, tokenizer, and label encoder needed \n",
    "#          for CNN model training or evaluation\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "# Load the trained tokenizer\n",
    "tokenizer_cnn = joblib.load('saved_models/tokenizer_cnn.pkl')\n",
    "\n",
    "# Load the padded sequences\n",
    "X_train_padded = joblib.load('datasets/X_train_padded.pkl')\n",
    "X_val_padded = joblib.load('datasets/X_val_padded.pkl')\n",
    "\n",
    "# Load the encoded labels\n",
    "y_train_encoded = joblib.load('datasets/y_train_encoded.pkl')\n",
    "y_val_encoded = joblib.load('datasets/y_val_encoded.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cb4bf6fb-3c48-45d5-9618-1383d3a85985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1743313824.255387   10807 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7168 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1743313825.785694   11198 service.cc:152] XLA service 0x75adf8004df0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1743313825.785719   11198 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce GTX 1080, Compute Capability 6.1\n",
      "2025-03-30 13:50:25.822454: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1743313826.105291   11198 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m   51/10350\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m31s\u001b[0m 3ms/step - accuracy: 0.5476 - loss: 0.6883"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1743313827.717531   11198 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 3ms/step - accuracy: 0.9116 - loss: 0.2023 - val_accuracy: 0.9573 - val_loss: 0.1040\n",
      "Epoch 2/5\n",
      "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 3ms/step - accuracy: 0.9672 - loss: 0.0884 - val_accuracy: 0.9625 - val_loss: 0.0980\n",
      "Epoch 3/5\n",
      "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 3ms/step - accuracy: 0.9797 - loss: 0.0557 - val_accuracy: 0.9592 - val_loss: 0.1029\n",
      "Epoch 4/5\n",
      "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 3ms/step - accuracy: 0.9858 - loss: 0.0381 - val_accuracy: 0.9606 - val_loss: 0.1061\n",
      "Epoch 5/5\n",
      "\u001b[1m10350/10350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 3ms/step - accuracy: 0.9912 - loss: 0.0260 - val_accuracy: 0.9567 - val_loss: 0.1160\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Step 2 - Define, compile, train, and save a CNN model for binary text classification\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "# Define model parameters\n",
    "VOCAB_SIZE = 10000\n",
    "EMBEDDING_DIM = 64\n",
    "\n",
    "# Create CNN model\n",
    "model_cnn = Sequential()\n",
    "model_cnn.add(Embedding(input_dim=VOCAB_SIZE, output_dim=EMBEDDING_DIM))\n",
    "model_cnn.add(Conv1D(filters=32, kernel_size=5, activation='relu'))\n",
    "model_cnn.add(MaxPooling1D(pool_size=2))\n",
    "#model_cnn.add(Conv1D(filters=16, kernel_size=5, activation='relu'))\n",
    "model_cnn.add(GlobalMaxPooling1D())\n",
    "model_cnn.add(Dropout(0.3))\n",
    "model_cnn.add(Dense(32, activation='relu'))\n",
    "model_cnn.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile model\n",
    "model_cnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "history = model_cnn.fit(\n",
    "    X_train_padded, y_train_encoded,\n",
    "    validation_data=(X_val_padded, y_val_encoded),\n",
    "    epochs=5,\n",
    "    batch_size=4,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Save model\n",
    "model_cnn.save('saved_models/model_cnn.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1bbee29f-1338-4854-9612-5231669c82ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "\u001b[1m\n",
      "Model 3: CNN (Deep Learning model)\n",
      "Validation Set:\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d36cf_row0_col2 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d36cf\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d36cf_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_d36cf_level0_col1\" class=\"col_heading level0 col1\" >Model name</th>\n",
       "      <th id=\"T_d36cf_level0_col2\" class=\"col_heading level0 col2\" >Accuracy</th>\n",
       "      <th id=\"T_d36cf_level0_col3\" class=\"col_heading level0 col3\" >Precision</th>\n",
       "      <th id=\"T_d36cf_level0_col4\" class=\"col_heading level0 col4\" >Recall</th>\n",
       "      <th id=\"T_d36cf_level0_col5\" class=\"col_heading level0 col5\" >F1 Score</th>\n",
       "      <th id=\"T_d36cf_level0_col6\" class=\"col_heading level0 col6\" >Model type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d36cf_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_d36cf_row0_col0\" class=\"data row0 col0\" >3</td>\n",
       "      <td id=\"T_d36cf_row0_col1\" class=\"data row0 col1\" >CNN</td>\n",
       "      <td id=\"T_d36cf_row0_col2\" class=\"data row0 col2\" >0.96</td>\n",
       "      <td id=\"T_d36cf_row0_col3\" class=\"data row0 col3\" >0.97</td>\n",
       "      <td id=\"T_d36cf_row0_col4\" class=\"data row0 col4\" >0.95</td>\n",
       "      <td id=\"T_d36cf_row0_col5\" class=\"data row0 col5\" >0.96</td>\n",
       "      <td id=\"T_d36cf_row0_col6\" class=\"data row0 col6\" >Deep Learning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x75aeb3d43520>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Real       0.95      0.97      0.96      2479\n",
      "        Fake       0.97      0.95      0.96      2696\n",
      "\n",
      "    accuracy                           0.96      5175\n",
      "   macro avg       0.96      0.96      0.96      5175\n",
      "weighted avg       0.96      0.96      0.96      5175\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Step 3 - Generate predictions and evaluate the CNN model on the validation set,\n",
    "#          and save predictions for stacking (ensemble) model later.\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "# Predictions for CNN Model (use padded sequences) for the validation set\n",
    "y_pred_proba_val_cnn = model_cnn.predict(X_val_padded)                                    # Original: (num_samples, 1)\n",
    "y_pred_proba_val_cnn = np.column_stack([1 - y_pred_proba_val_cnn, y_pred_proba_val_cnn])  # Ensure follow [p(Fake), p(Real)] explicitly\n",
    "y_pred_val_cnn = np.argmax(y_pred_proba_val_cnn, axis=1)                                  # Class labels\n",
    "\n",
    "# Save predicted probabilities for ensemble stacking\n",
    "joblib.dump(y_pred_proba_val_cnn, \"saved_predictions/y_pred_proba_val_cnn.pkl\")\n",
    "\n",
    "# Call function - to evaluate the effectiveness of the model\n",
    "model_num = 3\n",
    "model_name = 'CNN'\n",
    "model_type = 'Deep Learning'\n",
    "model_desc = f'Model {model_num}: {model_name} ({model_type} model)\\nValidation Set'\n",
    "result     = evaluate_model_performance(model_num, model_name, model_type, model_desc, y_val, y_pred_val_cnn)\n",
    "\n",
    "# Call function - to store validation results\n",
    "phase = 1                  # 1 for validation phase / 2 for testing phase\n",
    "test_set = 0               # test set 1 or 2 for testing phase\n",
    "first_model = False        # True for first model for that phase / False for subsequent model for the same phase\n",
    "store_evaluation_results(phase, test_set, first_model, model_num, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c2572d81-ac48-4401-b69f-d79c2b598f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Step 4 - Delete the CNN model and call garbage collection to release the memory held by Python\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "\n",
    "# Delete the model\n",
    "del model_cnn\n",
    "\n",
    "# Call garbage collection to free memory\n",
    "gc.collect()\n",
    "\n",
    "# Clear session\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe2162a-00b2-4eaf-a07c-8faec1d57f78",
   "metadata": {},
   "source": [
    "# 5. Feature Engineering and Transformer-Based Model\n",
    "\n",
    "# _A different kernel for PyTorch_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b82aba-0dec-43b4-b2e2-ec2f88686164",
   "metadata": {},
   "source": [
    "### ⚠️ **Note:** \n",
    "* Please switch to the **kernel** for **`pytorch`** before running this section.\n",
    "* This is required for BERT and RoBERTa models using the `transformers` and `torch` libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6444ddf0-773f-4285-8b00-72fe1cd6dfe6",
   "metadata": {},
   "source": [
    "## 5.1 Retrieval of Training, Validation and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30db2ac7-8964-4607-96d9-6cc44e59e328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Libraries\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "import joblib                                    # for saving models for future use and retrieval of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02d56a2e-88e2-4016-af8d-f82dc1c660ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Load X and y for training, validation and test sets, and label encoded sets \n",
    "# for BERT model training and evaluation\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "# Load X and y from training and validation sets\n",
    "X_train = joblib.load('datasets/X_train.pkl')\n",
    "y_train = joblib.load('datasets/y_train.pkl')\n",
    "X_val = joblib.load('datasets/X_val.pkl')\n",
    "y_val = joblib.load('datasets/y_val.pkl')\n",
    "\n",
    "# Load X and y from test sets\n",
    "X_test_1 = joblib.load('datasets/X_test_1.pkl')\n",
    "y_test_1 = joblib.load('datasets/y_test_1.pkl')\n",
    "X_test_2 = joblib.load('datasets/X_test_2.pkl')\n",
    "y_test_2 = joblib.load('datasets/y_test_2.pkl')\n",
    "\n",
    "# Load the encoded labels\n",
    "y_train_encoded = joblib.load('datasets/y_train_encoded.pkl')\n",
    "y_val_encoded = joblib.load('datasets/y_val_encoded.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985a39d6-1e1a-4066-bd98-03bf0286e1a1",
   "metadata": {},
   "source": [
    "## 5.2. Tokenisation for BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a024d93e-ab46-4a91-a010-8948786045af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seirokusan/anaconda3/envs/bert_torch_p39_22mar/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Libraries\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "from transformers import BertTokenizer             # Loads pretrained BERT tokenizer\n",
    "import torch                                       # PyTorch core library for tensors and models\n",
    "from torch.utils.data import Dataset, DataLoader   # For custom dataset and batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59e41c43-0359-4581-b5b8-f66493fb8e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# CLASS - A custom dataset for BERT and RoBERTa using tokenised inputs and labels\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "class NewsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e5ab21f-1f3e-4e9b-ae35-34aebf938a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Prepare and save BERT-tokenized training and validation data\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "# Load the BERT tokenizer\n",
    "tokenizer_bert = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Ensure X_train and X_val are lists of strings\n",
    "X_train_clean = X_train.astype(str).tolist()\n",
    "X_val_clean = X_val.astype(str).tolist()\n",
    "\n",
    "# Tokenize the data\n",
    "X_train_encodings_bert = tokenizer_bert(X_train_clean, truncation=True, padding=True, max_length=128)\n",
    "X_val_encodings_bert = tokenizer_bert(X_val_clean, truncation=True, padding=True, max_length=128)\n",
    "\n",
    "# Save the BERT tokenizer\n",
    "tokenizer_bert.save_pretrained(\"model_bert\")\n",
    "\n",
    "# Initialise training and validation sets with tokenised BERT inputs\n",
    "train_dataset_bert = NewsDataset(X_train_encodings_bert, y_train)\n",
    "val_dataset_bert = NewsDataset(X_val_encodings_bert, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774cbb1d-4cc0-4519-9fef-9a91c44acb20",
   "metadata": {},
   "source": [
    "## 5.3. Model 4: BERT - Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9319fbd1-35e2-469b-8d39-7f5ce0a79624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Libraries\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "from transformers import BertTokenizer                                    # Tokenise text for BERT\n",
    "from transformers import BertForSequenceClassification                    # BERT model for classification\n",
    "from transformers import TrainingArguments, Trainer                       # Hugging Face training tools\n",
    "import numpy as np                                                        # for numerical operations\n",
    "from importlib import reload                                              # to reload updated Python modules\n",
    "import utils.evaluate_model_performance                                   # import module (needed for reload)\n",
    "reload(utils.evaluate_model_performance)                                  # reload to reflect any latest changes in file\n",
    "from utils.evaluate_model_performance import evaluate_model_performance   # custom function to evaluate models\n",
    "import utils.store_evaluation_results                                     # import custom function (needed for reload)\n",
    "reload(utils.store_evaluation_results)                                    # reload to reflect any latest changes in file\n",
    "from utils.store_evaluation_results import store_evaluation_results       # custom function to store evaluation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8f85db6-029e-41d9-8767-037e7f3ebe15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Step 1 - Load BERT model\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "model_bert = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70581440-49b3-4c6c-b273-9ca7771b0af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Step 2 - FUNCTION - Define a simple accuracy computation for evaluation\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    acc = (preds == labels).mean()\n",
    "    return {'accuracy': acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d162c30-35ea-431a-b6c0-06b55a1645d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Step 3 - Clear unused GPU memory cache\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "792dd09f-859f-4091-a57c-af38076aa956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31050' max='31050' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31050/31050 1:08:06, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.177100</td>\n",
       "      <td>0.173332</td>\n",
       "      <td>0.962512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.076100</td>\n",
       "      <td>0.165509</td>\n",
       "      <td>0.965797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.057100</td>\n",
       "      <td>0.192833</td>\n",
       "      <td>0.971014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Step 4 - Train, evaluate, and save a BERT text classification model\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "# Set training configurations for BERT model\n",
    "training_args_bert = TrainingArguments(\n",
    "    output_dir='./bert-fake-news',          # output directory\n",
    "    eval_strategy='epoch',           # evaluate on each epoch end\n",
    "    save_strategy='epoch',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='eval_loss',     # choose best model based on validation loss\n",
    "    save_total_limit=1,# only keep 1 best model (to save disk)\n",
    "    report_to=[],\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Initialise Trainer to train and evaluate BERT model\n",
    "trainer_bert = Trainer(\n",
    "    model=model_bert,\n",
    "    args=training_args_bert,\n",
    "    train_dataset=train_dataset_bert,\n",
    "    eval_dataset=val_dataset_bert,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Train the BERT model\n",
    "trainer_bert.train()\n",
    "\n",
    "# Save the BERT model\n",
    "trainer_bert.save_model(\"model_bert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1df69050-f85f-41f2-8e47-29c5f7737f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "Model 4: BERT (Transformer-Based model)\n",
      "Validation Set:\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_39e05_row0_col2 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_39e05\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_39e05_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_39e05_level0_col1\" class=\"col_heading level0 col1\" >Model name</th>\n",
       "      <th id=\"T_39e05_level0_col2\" class=\"col_heading level0 col2\" >Accuracy</th>\n",
       "      <th id=\"T_39e05_level0_col3\" class=\"col_heading level0 col3\" >Precision</th>\n",
       "      <th id=\"T_39e05_level0_col4\" class=\"col_heading level0 col4\" >Recall</th>\n",
       "      <th id=\"T_39e05_level0_col5\" class=\"col_heading level0 col5\" >F1 Score</th>\n",
       "      <th id=\"T_39e05_level0_col6\" class=\"col_heading level0 col6\" >Model type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_39e05_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_39e05_row0_col0\" class=\"data row0 col0\" >4</td>\n",
       "      <td id=\"T_39e05_row0_col1\" class=\"data row0 col1\" >BERT</td>\n",
       "      <td id=\"T_39e05_row0_col2\" class=\"data row0 col2\" >0.97</td>\n",
       "      <td id=\"T_39e05_row0_col3\" class=\"data row0 col3\" >0.95</td>\n",
       "      <td id=\"T_39e05_row0_col4\" class=\"data row0 col4\" >0.99</td>\n",
       "      <td id=\"T_39e05_row0_col5\" class=\"data row0 col5\" >0.97</td>\n",
       "      <td id=\"T_39e05_row0_col6\" class=\"data row0 col6\" >Transformer-Based</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x71af0ae0b340>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Real       0.98      0.94      0.96      2479\n",
      "        Fake       0.95      0.99      0.97      2696\n",
      "\n",
      "    accuracy                           0.97      5175\n",
      "   macro avg       0.97      0.96      0.97      5175\n",
      "weighted avg       0.97      0.97      0.97      5175\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Step 5 - Generate predictions and evaluate the BERT model on the validation set\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "# Predictions for the validation set\n",
    "y_pred_proba_val_bert = trainer_bert.predict(val_dataset_bert)\n",
    "y_pred_val_bert = np.argmax(y_pred_proba_val_bert.predictions, axis=1)\n",
    "\n",
    "# Save predicted probabilities for ensemble stacking\n",
    "joblib.dump(y_pred_proba_val_bert.predictions, \"saved_predictions/y_pred_proba_val_bert.pkl\")\n",
    "\n",
    "# Call function - to evaluate the effectiveness of the model\n",
    "model_num = 4\n",
    "model_name = 'BERT'\n",
    "model_type = 'Transformer-Based'\n",
    "model_desc = f'Model {model_num}: {model_name} ({model_type} model)\\nValidation Set'\n",
    "result     = evaluate_model_performance(model_num, model_name, model_type, model_desc, y_val, y_pred_val_bert)\n",
    "\n",
    "# Call function - to store validation results\n",
    "phase = 1                  # 1 for validation phase / 2 for testing phase\n",
    "test_set = 0               # test set 1 or 2 for testing phase\n",
    "first_model = False        # True for first model for that phase / False for subsequent model for the same phase\n",
    "store_evaluation_results(phase, test_set, first_model, model_num, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81efacce-1cf4-4d64-a920-bdfb7021fb1d",
   "metadata": {},
   "source": [
    "## 5.4. Model 4: BERT - Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6607c00-fa75-44e1-89e0-c619daafa394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Libraries\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "import torch.nn.functional as F                                          # neural network functions (e.g., softmax, loss)\n",
    "from utils.evaluate_model_performance import evaluate_model_performance  # custom function to evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "633fe9ad-030a-4b55-b29a-492c481f62d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# FUNCTION - Generate class probabilities and predicted labels for the BERT model on the test set\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "def predict_bert_test_labels(X_test):\n",
    "    cleaned_inputs = [str(x) if x is not None else \"\" for x in X_test]  # Ensure all inputs are strings\n",
    "    model_test_bert.eval()                                              # Set model to evaluation mode\n",
    "    test_encodings_bert = tokenizer_test_bert(cleaned_inputs,           # Tokenise test inputs\n",
    "                                              truncation=True, \n",
    "                                              padding=True, \n",
    "                                              max_length=512, \n",
    "                                              return_tensors='pt')  \n",
    "    with torch.no_grad():                                               # Disable gradient calculation\n",
    "        outputs_bert = model_test_bert(**test_encodings_bert)           # Get model outputs\n",
    "    logits_test_bert = outputs_bert.logits                              # Raw model scores\n",
    "    probabilities_test_bert = F.softmax(logits_test_bert, dim=1)        # Convert to probabilities\n",
    "    y_pred_proba_test_bert = probabilities_test_bert.numpy()            # Convert to NumPy array\n",
    "    y_pred_test_bert = logits_test_bert.argmax(dim=1).numpy()           # Get predicted labels\n",
    "        \n",
    "    return y_pred_test_bert, y_pred_proba_test_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6d11eb7-8d96-43d4-811f-eebd5ed7092c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# FUNCTION - Loop through multiple test sets to generate predictions and evaluate model performance\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "def evaluate_model_bert_on_test_sets(model_num, model_name, model_type, test_sets):\n",
    "\n",
    "    test_num = 0\n",
    "\n",
    "    # Loop through each test set\n",
    "    for X_test, y_test in test_sets:\n",
    "\n",
    "        # Call function - to generate class probabilities and predicted labels\n",
    "        y_pred_test, y_pred_proba_test = predict_bert_test_labels(X_test)\n",
    "        print()\n",
    "\n",
    "        # Increment test_num by 1 (for Test 1 or Test 2 sets)\n",
    "        test_num += 1\n",
    "        if test_num == 1:\n",
    "            y_pred_test_1 = y_pred_test\n",
    "            y_pred_proba_test_1 = y_pred_proba_test\n",
    "            domain = 'News'\n",
    "        else:\n",
    "            y_pred_test_2 = y_pred_test\n",
    "            y_pred_proba_test_2 = y_pred_proba_test\n",
    "            domain = 'Football'\n",
    "        \n",
    "        # Call function - to evaluate the effectiveness of the model\n",
    "        model_desc = f'Model {model_num}: {model_name} ({model_type} model)\\nTest {test_num} Set ({domain} Domain)'\n",
    "        result = evaluate_model_performance(model_num, model_name, model_type, model_desc, y_test, y_pred_test)\n",
    "        print ()\n",
    "\n",
    "        # Save the results (Test 1 or Test 2 sets)\n",
    "        # Call function - to store test results\n",
    "        phase = 2                   # 1 for validation phase / 2 for testing phase\n",
    "        test_set = test_num         # test set 1 or 2 for testing phase\n",
    "        first_model = True          # True for first model for that phase / False for subsequent model for the same phase\n",
    "        store_evaluation_results(phase, test_set, first_model, model_num, result)\n",
    "\n",
    "    return y_pred_test_1, y_pred_proba_test_1, y_pred_test_2, y_pred_proba_test_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d00e643-933c-4101-92ff-2b0bd19c3cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\n",
      "Model 4: BERT (Transformer-Based model)\n",
      "Test 1 Set (News Domain):\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_fcea2_row0_col2 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_fcea2\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_fcea2_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_fcea2_level0_col1\" class=\"col_heading level0 col1\" >Model name</th>\n",
       "      <th id=\"T_fcea2_level0_col2\" class=\"col_heading level0 col2\" >Accuracy</th>\n",
       "      <th id=\"T_fcea2_level0_col3\" class=\"col_heading level0 col3\" >Precision</th>\n",
       "      <th id=\"T_fcea2_level0_col4\" class=\"col_heading level0 col4\" >Recall</th>\n",
       "      <th id=\"T_fcea2_level0_col5\" class=\"col_heading level0 col5\" >F1 Score</th>\n",
       "      <th id=\"T_fcea2_level0_col6\" class=\"col_heading level0 col6\" >Model type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_fcea2_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_fcea2_row0_col0\" class=\"data row0 col0\" >4</td>\n",
       "      <td id=\"T_fcea2_row0_col1\" class=\"data row0 col1\" >BERT</td>\n",
       "      <td id=\"T_fcea2_row0_col2\" class=\"data row0 col2\" >1.00</td>\n",
       "      <td id=\"T_fcea2_row0_col3\" class=\"data row0 col3\" >0.99</td>\n",
       "      <td id=\"T_fcea2_row0_col4\" class=\"data row0 col4\" >1.00</td>\n",
       "      <td id=\"T_fcea2_row0_col5\" class=\"data row0 col5\" >1.00</td>\n",
       "      <td id=\"T_fcea2_row0_col6\" class=\"data row0 col6\" >Transformer-Based</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x71af0ad3afd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Real       1.00      0.99      1.00       508\n",
      "        Fake       0.99      1.00      1.00       482\n",
      "\n",
      "    accuracy                           1.00       990\n",
      "   macro avg       1.00      1.00      1.00       990\n",
      "weighted avg       1.00      1.00      1.00       990\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\n",
      "Model 4: BERT (Transformer-Based model)\n",
      "Test 2 Set (Football Domain):\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_8b364_row0_col2 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_8b364\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_8b364_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_8b364_level0_col1\" class=\"col_heading level0 col1\" >Model name</th>\n",
       "      <th id=\"T_8b364_level0_col2\" class=\"col_heading level0 col2\" >Accuracy</th>\n",
       "      <th id=\"T_8b364_level0_col3\" class=\"col_heading level0 col3\" >Precision</th>\n",
       "      <th id=\"T_8b364_level0_col4\" class=\"col_heading level0 col4\" >Recall</th>\n",
       "      <th id=\"T_8b364_level0_col5\" class=\"col_heading level0 col5\" >F1 Score</th>\n",
       "      <th id=\"T_8b364_level0_col6\" class=\"col_heading level0 col6\" >Model type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_8b364_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_8b364_row0_col0\" class=\"data row0 col0\" >4</td>\n",
       "      <td id=\"T_8b364_row0_col1\" class=\"data row0 col1\" >BERT</td>\n",
       "      <td id=\"T_8b364_row0_col2\" class=\"data row0 col2\" >0.96</td>\n",
       "      <td id=\"T_8b364_row0_col3\" class=\"data row0 col3\" >0.94</td>\n",
       "      <td id=\"T_8b364_row0_col4\" class=\"data row0 col4\" >0.98</td>\n",
       "      <td id=\"T_8b364_row0_col5\" class=\"data row0 col5\" >0.96</td>\n",
       "      <td id=\"T_8b364_row0_col6\" class=\"data row0 col6\" >Transformer-Based</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x71af0817eb80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Real       0.98      0.93      0.95      2004\n",
      "        Fake       0.94      0.98      0.96      2182\n",
      "\n",
      "    accuracy                           0.96      4186\n",
      "   macro avg       0.96      0.96      0.96      4186\n",
      "weighted avg       0.96      0.96      0.96      4186\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['saved_predictions/y_pred_proba_test_2_bert.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Load the trained BERT model and evaluate its performance on multiple test sets\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "# Load the saved BERT model\n",
    "model_test_bert = BertForSequenceClassification.from_pretrained(\"model_bert\")\n",
    "tokenizer_test_bert = BertTokenizer.from_pretrained(\"model_bert\")\n",
    "\n",
    "# Test sets 1 and 2\n",
    "test_sets = [(X_test_1, y_test_1),   # Test set 1\n",
    "             (X_test_2, y_test_2)]   # Test set 2\n",
    "\n",
    "# Call function - to generate predictions and evaluate performance of CNN model\n",
    "model_num = 4\n",
    "model_name = 'BERT'\n",
    "model_type = 'Transformer-Based'\n",
    "(y_pred_test_1_bert, y_pred_proba_test_1_bert,\n",
    " y_pred_test_2_bert, y_pred_proba_test_2_bert) = evaluate_model_bert_on_test_sets(model_num, \n",
    "                                                                                  model_name, \n",
    "                                                                                  model_type,\n",
    "                                                                                  test_sets\n",
    ")\n",
    "\n",
    "# Save predicted probabilities for ensemble stacking (test sets 1 and 2)\n",
    "joblib.dump(y_pred_proba_test_1_bert, \"saved_predictions/y_pred_proba_test_1_bert.pkl\")\n",
    "joblib.dump(y_pred_proba_test_2_bert, \"saved_predictions/y_pred_proba_test_2_bert.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51cb3a4e-4457-46c9-8923-cbae25c2ce80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Delete the BERT model and tokenizer,\n",
    "# and call garbage collection to release the memory held by Python\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "import gc\n",
    "\n",
    "# Delete the BERT model and tokenizer\n",
    "del model_bert\n",
    "del model_test_bert\n",
    "del tokenizer_bert\n",
    "del tokenizer_test_bert\n",
    "\n",
    "# Call garbage collection to free memory\n",
    "gc.collect()\n",
    "\n",
    "# Clear session\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74919b2-69b6-41bb-acfb-1b8fc915ab33",
   "metadata": {},
   "source": [
    "# 6. Ensemble Model and Validation Accuracy Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ef2d70-1943-4322-b754-d3421f133c50",
   "metadata": {},
   "source": [
    "### ⚠️ **Note:** \n",
    "* Please switch back to the **kernel** for **`TensorFlow`** before continuing this section.\n",
    "* This is required for the CNN model that uses the `TensorFlow` libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8905fb3-cc50-420d-91d1-a20b51a1404d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Libraries\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "import joblib   # for saving models for future use and retrieval of models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c63a843-38a0-4e40-85d2-e7863ab2aa78",
   "metadata": {},
   "source": [
    "## 6.1. Retrieval of Training and Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "274d69be-7575-4f55-b8c9-827325ad25c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Load X and y for training and validation sets and predicted probabilities from other models\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "# Load X and y for training and validation sets\n",
    "X_train = joblib.load('datasets/X_train.pkl')\n",
    "y_train = joblib.load('datasets/y_train.pkl')\n",
    "X_val = joblib.load('datasets/X_val.pkl')\n",
    "y_val = joblib.load('datasets/y_val.pkl')\n",
    "\n",
    "# Load predicted probabilities for ensemble stacking (validation set)\n",
    "y_pred_proba_val_nb = joblib.load(\"saved_predictions/y_pred_proba_val_nb.pkl\")            # Model 1 (NB)\n",
    "y_pred_proba_val_lr = joblib.load(\"saved_predictions/y_pred_proba_val_lr.pkl\")            # Model 2 (LR)\n",
    "y_pred_proba_val_cnn = joblib.load(\"saved_predictions/y_pred_proba_val_cnn.pkl\")          # Model 3 (CNN)\n",
    "y_pred_proba_val_bert = joblib.load(\"saved_predictions/y_pred_proba_val_bert.pkl\")        # Model 4 (BERT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0a58e9-549b-4c76-88fc-e8aec0e5c1d8",
   "metadata": {},
   "source": [
    "## 6.2. Model 5: Stacking Ensemble (Meta Classifier) - Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69e0506d-03b1-4198-8db5-355e60295c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Libraries\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "import numpy as np                                                        # for numerical operations\n",
    "from sklearn.linear_model import LogisticRegression                       # Statistical model - Logistic Regression\n",
    "from importlib import reload                                              # to reload updated Python modules\n",
    "import utils.evaluate_model_performance                                   # import module (needed for reload)\n",
    "reload(utils.evaluate_model_performance)                                  # reload to reflect any latest changes in file\n",
    "from utils.evaluate_model_performance import evaluate_model_performance   # custom function to evaluate models\n",
    "import utils.store_evaluation_results                                     # import custom function (needed for reload)\n",
    "reload(utils.store_evaluation_results)                                    # reload to reflect any latest changes in file\n",
    "from utils.store_evaluation_results import store_evaluation_results       # custom function to store evaluation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47b0fdef-c8e8-4b7f-bde4-de30f11f688e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "Model 5: Stacking Ensemble (Meta Classifier model)\n",
      "Validation Set:\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_77f3c_row0_col2 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_77f3c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_77f3c_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_77f3c_level0_col1\" class=\"col_heading level0 col1\" >Model name</th>\n",
       "      <th id=\"T_77f3c_level0_col2\" class=\"col_heading level0 col2\" >Accuracy</th>\n",
       "      <th id=\"T_77f3c_level0_col3\" class=\"col_heading level0 col3\" >Precision</th>\n",
       "      <th id=\"T_77f3c_level0_col4\" class=\"col_heading level0 col4\" >Recall</th>\n",
       "      <th id=\"T_77f3c_level0_col5\" class=\"col_heading level0 col5\" >F1 Score</th>\n",
       "      <th id=\"T_77f3c_level0_col6\" class=\"col_heading level0 col6\" >Model type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_77f3c_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_77f3c_row0_col0\" class=\"data row0 col0\" >5</td>\n",
       "      <td id=\"T_77f3c_row0_col1\" class=\"data row0 col1\" >Stacking Ensemble</td>\n",
       "      <td id=\"T_77f3c_row0_col2\" class=\"data row0 col2\" >0.97</td>\n",
       "      <td id=\"T_77f3c_row0_col3\" class=\"data row0 col3\" >0.97</td>\n",
       "      <td id=\"T_77f3c_row0_col4\" class=\"data row0 col4\" >0.97</td>\n",
       "      <td id=\"T_77f3c_row0_col5\" class=\"data row0 col5\" >0.97</td>\n",
       "      <td id=\"T_77f3c_row0_col6\" class=\"data row0 col6\" >Meta Classifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7594465aa7c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Real       0.97      0.97      0.97      2479\n",
      "        Fake       0.97      0.97      0.97      2696\n",
      "\n",
      "    accuracy                           0.97      5175\n",
      "   macro avg       0.97      0.97      0.97      5175\n",
      "weighted avg       0.97      0.97      0.97      5175\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Stack predicted probabilities from multiple base models (Naïve Bayes, Logistic Regression, CNN, \n",
    "# and BERT). These probabilities are used as features to train a meta-model (Logistic \n",
    "# Regression). The meta-model learns to combine base model predictions for improved performance.\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "# Create a new feature matrix with probabilities of class 1 from each base model\n",
    "X_val_meta = np.column_stack((\n",
    "    y_pred_proba_val_nb[:, 1],        # Naïve Bayes probabilities\n",
    "    y_pred_proba_val_lr[:, 1],        # Logistic Regression probabilities\n",
    "    y_pred_proba_val_cnn[:, 1],       # CNN probabilities\n",
    "    y_pred_proba_val_bert[:, 1]       # BERT probabilities\n",
    "))\n",
    "\n",
    "# Train a Logistic Regression model on the stacked probabilities\n",
    "model_meta = LogisticRegression()\n",
    "model_meta.fit(X_val_meta, y_val)\n",
    "\n",
    "# Save the trained meta-model\n",
    "joblib.dump(model_meta, \"saved_models/model_meta.pkl\")\n",
    "\n",
    "# Evaluate on the validation set to predict and get probabilities using the meta-model\n",
    "y_pred_meta_val = model_meta.predict(X_val_meta)\n",
    "y_pred_proba_meta_val = model_meta.predict_proba(X_val_meta)\n",
    "\n",
    "# Call function - to evaluate the effectiveness of the model\n",
    "model_num = 5\n",
    "model_name = 'Stacking Ensemble'\n",
    "model_type = 'Meta Classifier'\n",
    "model_desc = f'Model {model_num}: {model_name} ({model_type} model)\\nValidation Set'\n",
    "result     = evaluate_model_performance(model_num, model_name, model_type, model_desc, y_val, y_pred_meta_val)\n",
    "\n",
    "# Call function - to store validation results\n",
    "phase = 1                  # 1 for validation phase / 2 for testing phase\n",
    "test_set = 0               # test set 1 or 2 for testing phase\n",
    "first_model = False        # True for first model for that phase / False for subsequent model for the same phase\n",
    "store_evaluation_results(phase, test_set, first_model, model_num, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412b0ced-17ed-4212-b97b-1d7603ac401b",
   "metadata": {},
   "source": [
    "## 6.3. Validation Scores Comparison for All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "241d9af9-1da6-4e92-9b1f-9a4c5d51a933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Libraries\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "import pandas as pd  # to read CSV files into pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e88674a-6675-4e64-91de-0eb7ac766cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# FUNCTION - Load saved model results on Validation, Test 1 or Test 2 Sets, \n",
    "#            combine them into a single DataFrame, style the 'Accuracy' column,\n",
    "#            and format all values to 2 decimal places, and display the styled table with a header\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "def load_and_display_metric_scores(file_path, table_desc):\n",
    "    # Load saved results\n",
    "    all_model_results = joblib.load(file_path)\n",
    "\n",
    "    # Combine into one DataFrame\n",
    "    final_results_df = pd.concat(all_model_results, ignore_index=True)\n",
    "\n",
    "    # Sort by 'Model' column in ascending order\n",
    "    final_results_df = final_results_df.sort_values(by='Model')\n",
    "    \n",
    "    # Style: bold 'Accuracy' column and format all values to 2 decimal places\n",
    "    styled_df = final_results_df.style \\\n",
    "        .map(lambda val: 'font-weight: bold', subset=['Accuracy']) \\\n",
    "        .format(precision=2)\n",
    "\n",
    "    # Display the full table with bolded Accuracy column\n",
    "    print(f'\\033[1m\\n{table_desc}\\n\\033[0m') \n",
    "    display(styled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59267183-cc10-445d-8582-76ca4f1d2f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "Validation Scores Comparison for All Models\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_020f7_row0_col2, #T_020f7_row1_col2, #T_020f7_row2_col2, #T_020f7_row3_col2, #T_020f7_row4_col2 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_020f7\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_020f7_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_020f7_level0_col1\" class=\"col_heading level0 col1\" >Model name</th>\n",
       "      <th id=\"T_020f7_level0_col2\" class=\"col_heading level0 col2\" >Accuracy</th>\n",
       "      <th id=\"T_020f7_level0_col3\" class=\"col_heading level0 col3\" >Precision</th>\n",
       "      <th id=\"T_020f7_level0_col4\" class=\"col_heading level0 col4\" >Recall</th>\n",
       "      <th id=\"T_020f7_level0_col5\" class=\"col_heading level0 col5\" >F1 Score</th>\n",
       "      <th id=\"T_020f7_level0_col6\" class=\"col_heading level0 col6\" >Model type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_020f7_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_020f7_row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "      <td id=\"T_020f7_row0_col1\" class=\"data row0 col1\" >Naive Bayes</td>\n",
       "      <td id=\"T_020f7_row0_col2\" class=\"data row0 col2\" >0.93</td>\n",
       "      <td id=\"T_020f7_row0_col3\" class=\"data row0 col3\" >0.94</td>\n",
       "      <td id=\"T_020f7_row0_col4\" class=\"data row0 col4\" >0.93</td>\n",
       "      <td id=\"T_020f7_row0_col5\" class=\"data row0 col5\" >0.94</td>\n",
       "      <td id=\"T_020f7_row0_col6\" class=\"data row0 col6\" >Baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_020f7_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_020f7_row1_col0\" class=\"data row1 col0\" >2</td>\n",
       "      <td id=\"T_020f7_row1_col1\" class=\"data row1 col1\" >Logistic Regression</td>\n",
       "      <td id=\"T_020f7_row1_col2\" class=\"data row1 col2\" >0.96</td>\n",
       "      <td id=\"T_020f7_row1_col3\" class=\"data row1 col3\" >0.96</td>\n",
       "      <td id=\"T_020f7_row1_col4\" class=\"data row1 col4\" >0.96</td>\n",
       "      <td id=\"T_020f7_row1_col5\" class=\"data row1 col5\" >0.96</td>\n",
       "      <td id=\"T_020f7_row1_col6\" class=\"data row1 col6\" >Traditional Machine Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_020f7_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_020f7_row2_col0\" class=\"data row2 col0\" >3</td>\n",
       "      <td id=\"T_020f7_row2_col1\" class=\"data row2 col1\" >CNN</td>\n",
       "      <td id=\"T_020f7_row2_col2\" class=\"data row2 col2\" >0.96</td>\n",
       "      <td id=\"T_020f7_row2_col3\" class=\"data row2 col3\" >0.97</td>\n",
       "      <td id=\"T_020f7_row2_col4\" class=\"data row2 col4\" >0.95</td>\n",
       "      <td id=\"T_020f7_row2_col5\" class=\"data row2 col5\" >0.96</td>\n",
       "      <td id=\"T_020f7_row2_col6\" class=\"data row2 col6\" >Deep Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_020f7_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_020f7_row3_col0\" class=\"data row3 col0\" >4</td>\n",
       "      <td id=\"T_020f7_row3_col1\" class=\"data row3 col1\" >BERT</td>\n",
       "      <td id=\"T_020f7_row3_col2\" class=\"data row3 col2\" >0.97</td>\n",
       "      <td id=\"T_020f7_row3_col3\" class=\"data row3 col3\" >0.95</td>\n",
       "      <td id=\"T_020f7_row3_col4\" class=\"data row3 col4\" >0.99</td>\n",
       "      <td id=\"T_020f7_row3_col5\" class=\"data row3 col5\" >0.97</td>\n",
       "      <td id=\"T_020f7_row3_col6\" class=\"data row3 col6\" >Transformer-Based</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_020f7_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_020f7_row4_col0\" class=\"data row4 col0\" >5</td>\n",
       "      <td id=\"T_020f7_row4_col1\" class=\"data row4 col1\" >Stacking Ensemble</td>\n",
       "      <td id=\"T_020f7_row4_col2\" class=\"data row4 col2\" >0.97</td>\n",
       "      <td id=\"T_020f7_row4_col3\" class=\"data row4 col3\" >0.97</td>\n",
       "      <td id=\"T_020f7_row4_col4\" class=\"data row4 col4\" >0.97</td>\n",
       "      <td id=\"T_020f7_row4_col5\" class=\"data row4 col5\" >0.97</td>\n",
       "      <td id=\"T_020f7_row4_col6\" class=\"data row4 col6\" >Meta Classifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x75948baefcd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Call function to load and display all model results on Validation set\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "file_path = 'results/all_model_results_val.pkl'\n",
    "table_desc = 'Validation Scores Comparison for All Models'\n",
    "load_and_display_metric_scores(file_path, table_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249f4817-9b5f-4372-9b4f-6ceab737e9e4",
   "metadata": {},
   "source": [
    "# 7. Test Set Evaluation and Accuracy Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a35208-d828-49dc-b184-90a5e0428fad",
   "metadata": {},
   "source": [
    "## 7.1. Retrieval of Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "323ddedc-c8d1-4b6a-a7ee-e7959d392798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Load test sets, including padded inputs and encoded labels, for evaluating the Naive Bayes, \n",
    "# Logistic Regression, CNN and Ensemble models\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "# Load X and y from test sets\n",
    "X_test_1 = joblib.load('datasets/X_test_1.pkl')\n",
    "y_test_1 = joblib.load('datasets/y_test_1.pkl')\n",
    "X_test_2 = joblib.load('datasets/X_test_2.pkl')\n",
    "y_test_2 = joblib.load('datasets/y_test_2.pkl')\n",
    "\n",
    "# Load TF-IDF transformed test sets - for models 1 (Naive Bayes) and 2 (Logistic Regression)\n",
    "X_test_1_tfidf = joblib.load('datasets/X_test_1_tfidf.pkl')\n",
    "X_test_2_tfidf = joblib.load('datasets/X_test_2_tfidf.pkl')\n",
    "\n",
    "# Load the padded sequences - for model 3 (CNN)\n",
    "X_test_1_padded = joblib.load('datasets/X_test_1_padded.pkl')\n",
    "X_test_2_padded = joblib.load('datasets/X_test_2_padded.pkl')\n",
    "\n",
    "# Load the encoded labels - for model 3 (CNN)\n",
    "y_test_1_encoded = joblib.load('datasets/y_test_1_encoded.pkl')\n",
    "y_test_2_encoded = joblib.load('datasets/y_test_2_encoded.pkl')\n",
    "\n",
    "# Load predicted probabilities for ensemble stacking (test sets 1 and 2) - for model 6 (Stacking)\n",
    "y_pred_proba_test_1_bert = joblib.load(\"saved_predictions/y_pred_proba_test_1_bert.pkl\")        # Model 4 (BERT) - Test set 1\n",
    "y_pred_proba_test_2_bert = joblib.load(\"saved_predictions/y_pred_proba_test_2_bert.pkl\")        # Model 4 (BERT) - Test set 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff3274e-895b-4690-aa41-0e286d49121a",
   "metadata": {},
   "source": [
    "## 7.2. General Evaluation Function for Multiple Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f179a59a-f74e-4375-85cd-bc3945903691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Libraries\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "from utils.evaluate_model_performance import evaluate_model_performance  # custom function to evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20a717f3-815d-4eab-b74c-d54e1ffde18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# FUNCTION - Loop through multiple test sets to generate predictions and evaluate model performance\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "def evaluate_model_on_test_sets(model_num, model_name, model_type, model_desc, test_sets):\n",
    "\n",
    "    test_num = 0\n",
    "\n",
    "    # Loop through each test set\n",
    "    for X_test, y_test in test_sets:\n",
    "\n",
    "        # Call respective functions - to generate class probabilities and predicted labels\n",
    "        # For model 1 (Naive Bayes)\n",
    "        if model_num == 1:\n",
    "            y_pred_test, y_pred_proba_test = predict_nb_test_labels(X_test)\n",
    "\n",
    "        # For model 2 (Logistic Regression)\n",
    "        elif model_num == 2:\n",
    "            y_pred_test, y_pred_proba_test = predict_lr_test_labels(X_test)\n",
    "\n",
    "        # For model 3 (CNN)\n",
    "        elif model_num == 3:\n",
    "            y_pred_test, y_pred_proba_test = predict_cnn_test_labels(X_test)\n",
    "\n",
    "        # Increment test_num by 1 (for Test 1 or Test 2 sets)\n",
    "        test_num += 1\n",
    "        if test_num == 1:\n",
    "            y_pred_test_1 = y_pred_test\n",
    "            y_pred_proba_test_1 = y_pred_proba_test\n",
    "            domain = 'News'\n",
    "        else:\n",
    "            y_pred_test_2 = y_pred_test\n",
    "            y_pred_proba_test_2 = y_pred_proba_test\n",
    "            domain = 'Football'\n",
    "        \n",
    "        # Call function - to evaluate the effectiveness of the model\n",
    "        model_desc2 = model_desc + f'\\nTest {str(test_num)} Set ({domain} Domain)'\n",
    "        result = evaluate_model_performance(model_num, model_name, model_type, model_desc2, y_test, y_pred_test)\n",
    "        print ()\n",
    "\n",
    "        # Save the results (Test 1 or Test 2 sets)\n",
    "        # Call function - to store test results\n",
    "        phase = 2                   # 1 for validation phase / 2 for testing phase\n",
    "        test_set = test_num         # test set 1 or 2 for testing phase\n",
    "        first_model = False         # True for first model for that phase / False for subsequent model for the same phase\n",
    "        store_evaluation_results(phase, test_set, first_model, model_num, result)\n",
    "    \n",
    "    return y_pred_test_1, y_pred_proba_test_1, y_pred_test_2, y_pred_proba_test_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf576de-ef45-454f-81c8-568b1f22b0a2",
   "metadata": {},
   "source": [
    "## 7.3. Model 1: Naive Bayes - Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2d0f906-9c24-4b0c-b983-4daeab377e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Libraries\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "from sklearn.naive_bayes import MultinomialNB         # Multinomial Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3ff601a-c22a-496a-89dd-dff8a2ee4015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# FUNCTION - Generate class probabilities and predicted labels for the Naive Bayes model \n",
    "#            on the test set\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "def predict_nb_test_labels(X_test_tfidf):\n",
    "    y_pred_nb_test = model_test_nb.predict(X_test_tfidf)\n",
    "    y_pred_proba_nb_test = model_test_nb.predict_proba(X_test_tfidf.toarray())\n",
    "    return y_pred_nb_test, y_pred_proba_nb_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd675a56-503d-48a6-9116-3b1c1f0501a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "Model 1: Naive Bayes (Baseline model) using TF-IDF Vectoriser\n",
      "Test 1 Set (News Domain):\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_de04a_row0_col2 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_de04a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_de04a_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_de04a_level0_col1\" class=\"col_heading level0 col1\" >Model name</th>\n",
       "      <th id=\"T_de04a_level0_col2\" class=\"col_heading level0 col2\" >Accuracy</th>\n",
       "      <th id=\"T_de04a_level0_col3\" class=\"col_heading level0 col3\" >Precision</th>\n",
       "      <th id=\"T_de04a_level0_col4\" class=\"col_heading level0 col4\" >Recall</th>\n",
       "      <th id=\"T_de04a_level0_col5\" class=\"col_heading level0 col5\" >F1 Score</th>\n",
       "      <th id=\"T_de04a_level0_col6\" class=\"col_heading level0 col6\" >Model type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_de04a_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_de04a_row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "      <td id=\"T_de04a_row0_col1\" class=\"data row0 col1\" >Naive Bayes</td>\n",
       "      <td id=\"T_de04a_row0_col2\" class=\"data row0 col2\" >0.94</td>\n",
       "      <td id=\"T_de04a_row0_col3\" class=\"data row0 col3\" >0.99</td>\n",
       "      <td id=\"T_de04a_row0_col4\" class=\"data row0 col4\" >0.88</td>\n",
       "      <td id=\"T_de04a_row0_col5\" class=\"data row0 col5\" >0.93</td>\n",
       "      <td id=\"T_de04a_row0_col6\" class=\"data row0 col6\" >Baseline</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x759442bb50a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Real       0.90      0.99      0.94       508\n",
      "        Fake       0.99      0.88      0.93       482\n",
      "\n",
      "    accuracy                           0.94       990\n",
      "   macro avg       0.95      0.94      0.94       990\n",
      "weighted avg       0.94      0.94      0.94       990\n",
      "\n",
      "\n",
      "\u001b[1m\n",
      "Model 1: Naive Bayes (Baseline model) using TF-IDF Vectoriser\n",
      "Test 2 Set (Football Domain):\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_39028_row0_col2 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_39028\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_39028_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_39028_level0_col1\" class=\"col_heading level0 col1\" >Model name</th>\n",
       "      <th id=\"T_39028_level0_col2\" class=\"col_heading level0 col2\" >Accuracy</th>\n",
       "      <th id=\"T_39028_level0_col3\" class=\"col_heading level0 col3\" >Precision</th>\n",
       "      <th id=\"T_39028_level0_col4\" class=\"col_heading level0 col4\" >Recall</th>\n",
       "      <th id=\"T_39028_level0_col5\" class=\"col_heading level0 col5\" >F1 Score</th>\n",
       "      <th id=\"T_39028_level0_col6\" class=\"col_heading level0 col6\" >Model type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_39028_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_39028_row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "      <td id=\"T_39028_row0_col1\" class=\"data row0 col1\" >Naive Bayes</td>\n",
       "      <td id=\"T_39028_row0_col2\" class=\"data row0 col2\" >0.93</td>\n",
       "      <td id=\"T_39028_row0_col3\" class=\"data row0 col3\" >0.93</td>\n",
       "      <td id=\"T_39028_row0_col4\" class=\"data row0 col4\" >0.94</td>\n",
       "      <td id=\"T_39028_row0_col5\" class=\"data row0 col5\" >0.93</td>\n",
       "      <td id=\"T_39028_row0_col6\" class=\"data row0 col6\" >Baseline</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7594429b7940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Real       0.94      0.92      0.93      2004\n",
      "        Fake       0.93      0.94      0.93      2182\n",
      "\n",
      "    accuracy                           0.93      4186\n",
      "   macro avg       0.93      0.93      0.93      4186\n",
      "weighted avg       0.93      0.93      0.93      4186\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Load the trained Naive Bayes model and evaluate its performance on multiple test sets\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "# Load the saved Naive Bayes model\n",
    "model_test_nb = joblib.load(\"saved_models/model_nb.pkl\")\n",
    "\n",
    "# Test sets 1 and 2\n",
    "test_sets = [(X_test_1_tfidf, y_test_1),   # Test set 1\n",
    "             (X_test_2_tfidf, y_test_2)]   # Test set 2\n",
    "\n",
    "# Call function - to generate predictions and evaluate performance of Naive Bayes model\n",
    "model_num = 1\n",
    "model_name = 'Naive Bayes'\n",
    "model_type = 'Baseline'\n",
    "model_desc = f'Model {model_num}: {model_name} ({model_type} model) using TF-IDF Vectoriser'\n",
    "y_pred_test_1_nb, y_pred_proba_test_1_nb, y_pred_test_2_nb, y_pred_proba_test_2_nb = evaluate_model_on_test_sets(model_num, \n",
    "                                                                                                                 model_name, \n",
    "                                                                                                                 model_type,\n",
    "                                                                                                                 model_desc,\n",
    "                                                                                                                 test_sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16274c65-1521-429b-97ce-fe711fdfe59f",
   "metadata": {},
   "source": [
    "## 7.4. Model 2: Logistic Regression - Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36e9e451-1c84-413c-a427-708230047d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Libraries\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "from sklearn.linear_model import LogisticRegression   # Statistical model - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10684746-e940-4ea5-b2af-f45fe2d875e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# FUNCTION - Generate class probabilities and predicted labels for the Logistic Regression model \n",
    "#            on the test set\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "def predict_lr_test_labels(X_test_tfidf):\n",
    "    y_pred_lr_test = model_test_lr_best.predict(X_test_tfidf)\n",
    "    y_pred_proba_lr_test = model_test_lr_best.predict_proba(X_test_tfidf.toarray())\n",
    "    return y_pred_lr_test, y_pred_proba_lr_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1306dfd9-0d62-4fbb-aa3b-74b851e422aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "Model 2: Logistic Regression (Traditional Machine Learning model) using TF-IDF Vectoriser\n",
      "Test 1 Set (News Domain):\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_428e6_row0_col2 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_428e6\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_428e6_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_428e6_level0_col1\" class=\"col_heading level0 col1\" >Model name</th>\n",
       "      <th id=\"T_428e6_level0_col2\" class=\"col_heading level0 col2\" >Accuracy</th>\n",
       "      <th id=\"T_428e6_level0_col3\" class=\"col_heading level0 col3\" >Precision</th>\n",
       "      <th id=\"T_428e6_level0_col4\" class=\"col_heading level0 col4\" >Recall</th>\n",
       "      <th id=\"T_428e6_level0_col5\" class=\"col_heading level0 col5\" >F1 Score</th>\n",
       "      <th id=\"T_428e6_level0_col6\" class=\"col_heading level0 col6\" >Model type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_428e6_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_428e6_row0_col0\" class=\"data row0 col0\" >2</td>\n",
       "      <td id=\"T_428e6_row0_col1\" class=\"data row0 col1\" >Logistic Regression</td>\n",
       "      <td id=\"T_428e6_row0_col2\" class=\"data row0 col2\" >0.99</td>\n",
       "      <td id=\"T_428e6_row0_col3\" class=\"data row0 col3\" >0.99</td>\n",
       "      <td id=\"T_428e6_row0_col4\" class=\"data row0 col4\" >0.99</td>\n",
       "      <td id=\"T_428e6_row0_col5\" class=\"data row0 col5\" >0.99</td>\n",
       "      <td id=\"T_428e6_row0_col6\" class=\"data row0 col6\" >Traditional Machine Learning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x759442a7c070>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Real       0.99      0.99      0.99       508\n",
      "        Fake       0.99      0.99      0.99       482\n",
      "\n",
      "    accuracy                           0.99       990\n",
      "   macro avg       0.99      0.99      0.99       990\n",
      "weighted avg       0.99      0.99      0.99       990\n",
      "\n",
      "\n",
      "\u001b[1m\n",
      "Model 2: Logistic Regression (Traditional Machine Learning model) using TF-IDF Vectoriser\n",
      "Test 2 Set (Football Domain):\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e7e2b_row0_col2 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e7e2b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e7e2b_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_e7e2b_level0_col1\" class=\"col_heading level0 col1\" >Model name</th>\n",
       "      <th id=\"T_e7e2b_level0_col2\" class=\"col_heading level0 col2\" >Accuracy</th>\n",
       "      <th id=\"T_e7e2b_level0_col3\" class=\"col_heading level0 col3\" >Precision</th>\n",
       "      <th id=\"T_e7e2b_level0_col4\" class=\"col_heading level0 col4\" >Recall</th>\n",
       "      <th id=\"T_e7e2b_level0_col5\" class=\"col_heading level0 col5\" >F1 Score</th>\n",
       "      <th id=\"T_e7e2b_level0_col6\" class=\"col_heading level0 col6\" >Model type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e7e2b_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_e7e2b_row0_col0\" class=\"data row0 col0\" >2</td>\n",
       "      <td id=\"T_e7e2b_row0_col1\" class=\"data row0 col1\" >Logistic Regression</td>\n",
       "      <td id=\"T_e7e2b_row0_col2\" class=\"data row0 col2\" >0.95</td>\n",
       "      <td id=\"T_e7e2b_row0_col3\" class=\"data row0 col3\" >0.95</td>\n",
       "      <td id=\"T_e7e2b_row0_col4\" class=\"data row0 col4\" >0.95</td>\n",
       "      <td id=\"T_e7e2b_row0_col5\" class=\"data row0 col5\" >0.95</td>\n",
       "      <td id=\"T_e7e2b_row0_col6\" class=\"data row0 col6\" >Traditional Machine Learning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x759442bca760>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Real       0.95      0.95      0.95      2004\n",
      "        Fake       0.95      0.95      0.95      2182\n",
      "\n",
      "    accuracy                           0.95      4186\n",
      "   macro avg       0.95      0.95      0.95      4186\n",
      "weighted avg       0.95      0.95      0.95      4186\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Load the trained Logistic Regression model and evaluate its performance on multiple test sets\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "# Load the saved Logistic Regression model\n",
    "model_test_lr_best = joblib.load(\"saved_models/model_lr_best.pkl\")\n",
    "\n",
    "# Test sets 1 and 2\n",
    "test_sets = [(X_test_1_tfidf, y_test_1),   # Test set 1\n",
    "             (X_test_2_tfidf, y_test_2)]   # Test set 2\n",
    "\n",
    "# Call function - to generate predictions and evaluate performance of Logistic Regression model\n",
    "model_num = 2\n",
    "model_name = 'Logistic Regression'\n",
    "model_type = 'Traditional Machine Learning'\n",
    "model_desc = f'Model {model_num}: {model_name} ({model_type} model) using TF-IDF Vectoriser'\n",
    "y_pred_test_1_lr, y_pred_proba_test_1_lr, y_pred_test_2_lr, y_pred_proba_test_2_lr = evaluate_model_on_test_sets(model_num, \n",
    "                                                                                                                 model_name, \n",
    "                                                                                                                 model_type,\n",
    "                                                                                                                 model_desc,\n",
    "                                                                                                                 test_sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdae7683-778e-4499-aeb8-74c44be36fba",
   "metadata": {},
   "source": [
    "## 7.5. Model 3: CNN - Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a55e9196-3fe7-47a2-bc8c-e63e7cd4367d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 15:26:42.862860: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743319602.884887   19178 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743319602.889837   19178 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743319602.902723   19178 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743319602.902751   19178 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743319602.902754   19178 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743319602.902756   19178 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-30 15:26:42.908067: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Libraries\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "import tensorflow as tf                          # for deep learning models\n",
    "from tensorflow.keras.models import load_model   # load a saved Keras model\n",
    "import numpy as np                               # for numerical operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0f45903-747d-4387-82f0-928e9e8cbaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# FUNCTION - Generate class probabilities and predicted labels for the CNN model on the test set\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "def predict_cnn_test_labels(X_test_padded):\n",
    "    y_pred_proba_cnn_test = model_test_cnn.predict(X_test_padded)                                # Original: (num_samples, 1)\n",
    "    y_pred_proba_cnn_test = np.column_stack([1 - y_pred_proba_cnn_test, y_pred_proba_cnn_test])  # Convert to (num_samples, 2)\n",
    "    y_pred_cnn_test = np.argmax(y_pred_proba_cnn_test, axis=1)                                   # Class labels    \n",
    "    return y_pred_cnn_test, y_pred_proba_cnn_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5de3850-d1f6-4785-b082-6b41491c1f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1743319605.190024   19178 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7220 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1743319607.764023   19354 service.cc:152] XLA service 0x759358006050 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1743319607.764045   19354 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce GTX 1080, Compute Capability 6.1\n",
      "2025-03-30 15:26:47.775359: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1743319607.804159   19354 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 562ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1743319608.246203   19354 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
      "\u001b[1m\n",
      "Model 3: CNN (Deep Learning model)\n",
      "Test 1 Set (News Domain):\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d8859_row0_col2 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d8859\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d8859_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_d8859_level0_col1\" class=\"col_heading level0 col1\" >Model name</th>\n",
       "      <th id=\"T_d8859_level0_col2\" class=\"col_heading level0 col2\" >Accuracy</th>\n",
       "      <th id=\"T_d8859_level0_col3\" class=\"col_heading level0 col3\" >Precision</th>\n",
       "      <th id=\"T_d8859_level0_col4\" class=\"col_heading level0 col4\" >Recall</th>\n",
       "      <th id=\"T_d8859_level0_col5\" class=\"col_heading level0 col5\" >F1 Score</th>\n",
       "      <th id=\"T_d8859_level0_col6\" class=\"col_heading level0 col6\" >Model type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d8859_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_d8859_row0_col0\" class=\"data row0 col0\" >3</td>\n",
       "      <td id=\"T_d8859_row0_col1\" class=\"data row0 col1\" >CNN</td>\n",
       "      <td id=\"T_d8859_row0_col2\" class=\"data row0 col2\" >1.00</td>\n",
       "      <td id=\"T_d8859_row0_col3\" class=\"data row0 col3\" >1.00</td>\n",
       "      <td id=\"T_d8859_row0_col4\" class=\"data row0 col4\" >1.00</td>\n",
       "      <td id=\"T_d8859_row0_col5\" class=\"data row0 col5\" >1.00</td>\n",
       "      <td id=\"T_d8859_row0_col6\" class=\"data row0 col6\" >Deep Learning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7593f410cca0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Real       1.00      1.00      1.00       508\n",
      "        Fake       1.00      1.00      1.00       482\n",
      "\n",
      "    accuracy                           1.00       990\n",
      "   macro avg       1.00      1.00      1.00       990\n",
      "weighted avg       1.00      1.00      1.00       990\n",
      "\n",
      "\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "\u001b[1m\n",
      "Model 3: CNN (Deep Learning model)\n",
      "Test 2 Set (Football Domain):\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_7c8af_row0_col2 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_7c8af\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_7c8af_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_7c8af_level0_col1\" class=\"col_heading level0 col1\" >Model name</th>\n",
       "      <th id=\"T_7c8af_level0_col2\" class=\"col_heading level0 col2\" >Accuracy</th>\n",
       "      <th id=\"T_7c8af_level0_col3\" class=\"col_heading level0 col3\" >Precision</th>\n",
       "      <th id=\"T_7c8af_level0_col4\" class=\"col_heading level0 col4\" >Recall</th>\n",
       "      <th id=\"T_7c8af_level0_col5\" class=\"col_heading level0 col5\" >F1 Score</th>\n",
       "      <th id=\"T_7c8af_level0_col6\" class=\"col_heading level0 col6\" >Model type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_7c8af_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_7c8af_row0_col0\" class=\"data row0 col0\" >3</td>\n",
       "      <td id=\"T_7c8af_row0_col1\" class=\"data row0 col1\" >CNN</td>\n",
       "      <td id=\"T_7c8af_row0_col2\" class=\"data row0 col2\" >0.94</td>\n",
       "      <td id=\"T_7c8af_row0_col3\" class=\"data row0 col3\" >0.96</td>\n",
       "      <td id=\"T_7c8af_row0_col4\" class=\"data row0 col4\" >0.94</td>\n",
       "      <td id=\"T_7c8af_row0_col5\" class=\"data row0 col5\" >0.95</td>\n",
       "      <td id=\"T_7c8af_row0_col6\" class=\"data row0 col6\" >Deep Learning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7593f410cbe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Real       0.93      0.95      0.94      2004\n",
      "        Fake       0.96      0.94      0.95      2182\n",
      "\n",
      "    accuracy                           0.94      4186\n",
      "   macro avg       0.94      0.94      0.94      4186\n",
      "weighted avg       0.94      0.94      0.94      4186\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Load the trained CNN model and evaluate its performance on multiple test sets\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "# Load the saved CNN model\n",
    "model_test_cnn = load_model(\"saved_models/model_cnn.keras\")\n",
    "\n",
    "# Test sets 1 and 2\n",
    "test_sets = [(X_test_1_padded, y_test_1),   # Test set 1\n",
    "             (X_test_2_padded, y_test_2)]   # Test set 2\n",
    "\n",
    "# Call function - to generate predictions and evaluate performance of CNN model\n",
    "model_num = 3\n",
    "model_name = 'CNN'\n",
    "model_type = 'Deep Learning'\n",
    "model_desc = f'Model {model_num}: {model_name} ({model_type} model)'\n",
    "y_pred_test_1_cnn, y_pred_proba_test_1_cnn, y_pred_test_2_cnn, y_pred_proba_test_2_cnn = evaluate_model_on_test_sets(model_num, \n",
    "                                                                                                                     model_name, \n",
    "                                                                                                                     model_type,\n",
    "                                                                                                                     model_desc,\n",
    "                                                                                                                     test_sets)\n",
    "\n",
    "# Clear session to release memory\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a206fa0-b9cf-49c1-88f4-7f448d1ffe3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Step 3 - Delete the CNN test model and call garbage collection to release the memory held by Python\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "\n",
    "# Delete the CNN test model\n",
    "del model_test_cnn\n",
    "\n",
    "# Call garbage collection to free memory\n",
    "gc.collect()\n",
    "\n",
    "# Clear session\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce04e82-6e0b-46a1-979e-08e351d79efe",
   "metadata": {},
   "source": [
    "## 7.6. Model 5: Stacking Ensemble - Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9acc071-269e-42d1-ae73-c4651dce1b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "Model 5: Stacking Ensemble (Meta Classifier model)\n",
      "Test 1 Set:\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_61baa_row0_col2 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_61baa\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_61baa_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_61baa_level0_col1\" class=\"col_heading level0 col1\" >Model name</th>\n",
       "      <th id=\"T_61baa_level0_col2\" class=\"col_heading level0 col2\" >Accuracy</th>\n",
       "      <th id=\"T_61baa_level0_col3\" class=\"col_heading level0 col3\" >Precision</th>\n",
       "      <th id=\"T_61baa_level0_col4\" class=\"col_heading level0 col4\" >Recall</th>\n",
       "      <th id=\"T_61baa_level0_col5\" class=\"col_heading level0 col5\" >F1 Score</th>\n",
       "      <th id=\"T_61baa_level0_col6\" class=\"col_heading level0 col6\" >Model type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_61baa_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_61baa_row0_col0\" class=\"data row0 col0\" >5</td>\n",
       "      <td id=\"T_61baa_row0_col1\" class=\"data row0 col1\" >Stacking Ensemble</td>\n",
       "      <td id=\"T_61baa_row0_col2\" class=\"data row0 col2\" >1.00</td>\n",
       "      <td id=\"T_61baa_row0_col3\" class=\"data row0 col3\" >1.00</td>\n",
       "      <td id=\"T_61baa_row0_col4\" class=\"data row0 col4\" >1.00</td>\n",
       "      <td id=\"T_61baa_row0_col5\" class=\"data row0 col5\" >1.00</td>\n",
       "      <td id=\"T_61baa_row0_col6\" class=\"data row0 col6\" >Meta Classifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x75944299aca0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Real       1.00      1.00      1.00       508\n",
      "        Fake       1.00      1.00      1.00       482\n",
      "\n",
      "    accuracy                           1.00       990\n",
      "   macro avg       1.00      1.00      1.00       990\n",
      "weighted avg       1.00      1.00      1.00       990\n",
      "\n",
      "\u001b[1m\n",
      "Model 5: Stacking Ensemble (Meta Classifier model)\n",
      "Test 2 Set:\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_0b67d_row0_col2 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_0b67d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_0b67d_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_0b67d_level0_col1\" class=\"col_heading level0 col1\" >Model name</th>\n",
       "      <th id=\"T_0b67d_level0_col2\" class=\"col_heading level0 col2\" >Accuracy</th>\n",
       "      <th id=\"T_0b67d_level0_col3\" class=\"col_heading level0 col3\" >Precision</th>\n",
       "      <th id=\"T_0b67d_level0_col4\" class=\"col_heading level0 col4\" >Recall</th>\n",
       "      <th id=\"T_0b67d_level0_col5\" class=\"col_heading level0 col5\" >F1 Score</th>\n",
       "      <th id=\"T_0b67d_level0_col6\" class=\"col_heading level0 col6\" >Model type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_0b67d_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_0b67d_row0_col0\" class=\"data row0 col0\" >5</td>\n",
       "      <td id=\"T_0b67d_row0_col1\" class=\"data row0 col1\" >Stacking Ensemble</td>\n",
       "      <td id=\"T_0b67d_row0_col2\" class=\"data row0 col2\" >0.96</td>\n",
       "      <td id=\"T_0b67d_row0_col3\" class=\"data row0 col3\" >0.97</td>\n",
       "      <td id=\"T_0b67d_row0_col4\" class=\"data row0 col4\" >0.95</td>\n",
       "      <td id=\"T_0b67d_row0_col5\" class=\"data row0 col5\" >0.96</td>\n",
       "      <td id=\"T_0b67d_row0_col6\" class=\"data row0 col6\" >Meta Classifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7593f4150a30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Real       0.95      0.97      0.96      2004\n",
      "        Fake       0.97      0.95      0.96      2182\n",
      "\n",
      "    accuracy                           0.96      4186\n",
      "   macro avg       0.96      0.96      0.96      4186\n",
      "weighted avg       0.96      0.96      0.96      4186\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Stack predicted probabilities from multiple base models (Naïve Bayes, Logistic Regression, CNN, \n",
    "# BERT, and RoBERTa). These probabilities are used as features to train a meta-model (Logistic \n",
    "# Regression). The meta-model learns to combine base model predictions for improved performance.\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "# Create new feature matrices with probabilities of class 1 from each base model\n",
    "# For Test set 1\n",
    "X_test_1_meta = np.column_stack((\n",
    "    y_pred_proba_test_1_nb[:, 1],        # Naïve Bayes probabilities\n",
    "    y_pred_proba_test_1_lr[:, 1],        # Logistic Regression probabilities\n",
    "    y_pred_proba_test_1_cnn[:, 1],       # CNN probabilities\n",
    "    y_pred_proba_test_1_bert[:, 1]       # BERT probabilities\n",
    "))\n",
    "\n",
    "# For Test set 2\n",
    "X_test_2_meta = np.column_stack((\n",
    "    y_pred_proba_test_2_nb[:, 1],        # Naïve Bayes probabilities\n",
    "    y_pred_proba_test_2_lr[:, 1],        # Logistic Regression probabilities\n",
    "    y_pred_proba_test_2_cnn[:, 1],       # CNN probabilities\n",
    "    y_pred_proba_test_2_bert[:, 1]       # BERT probabilities\n",
    "))\n",
    "\n",
    "# Store test meta features in a labelled dictionary\n",
    "X_test_meta_sets = {\n",
    "    \"Test 1 Dataset\": X_test_1_meta,\n",
    "    \"Test 2 Dataset\": X_test_2_meta\n",
    "}\n",
    "\n",
    "test_num = 0\n",
    "\n",
    "# Loop through test sets to predict and evaluate model\n",
    "for label, X_meta in X_test_meta_sets.items():\n",
    "    # Make predictions on test data using the meta model\n",
    "    y_pred_test_meta = model_meta.predict(X_meta)\n",
    "\n",
    "    # Increment test_num\n",
    "    test_num += 1\n",
    "    if test_num == 1:\n",
    "        y_test = y_test_1\n",
    "    else:\n",
    "        y_test = y_test_2\n",
    "    \n",
    "    # Call function - to evaluate the effectiveness of the model\n",
    "    model_num = 5\n",
    "    model_name = 'Stacking Ensemble'\n",
    "    model_type = 'Meta Classifier'\n",
    "    model_desc = f'Model {model_num}: {model_name} ({model_type} model)\\nTest {str(test_num)} Set'\n",
    "    result = evaluate_model_performance(model_num, model_name, model_type, model_desc, y_test, y_pred_test_meta)\n",
    "\n",
    "    # Save the results (Test 1 or Test 2 sets)\n",
    "    # Call function - to store test results\n",
    "    phase = 2                   # 1 for validation phase / 2 for testing phase\n",
    "    test_set = test_num         # test set 1 or 2 for testing phase\n",
    "    first_model = False         # True for first model for that phase / False for subsequent model for the same phase\n",
    "    store_evaluation_results(phase, test_set, first_model, model_num, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7a0d77-df8a-46b9-8c30-76448265040d",
   "metadata": {},
   "source": [
    "## 7.7. Test Scores Comparison for All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd5259f1-2b3a-46ed-8b68-4a4d914c95a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "Test Scores Comparison for All Models - Test 1 Set (News Domain)\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a8cf4_row0_col2, #T_a8cf4_row1_col2, #T_a8cf4_row2_col2, #T_a8cf4_row3_col2, #T_a8cf4_row4_col2 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a8cf4\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a8cf4_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_a8cf4_level0_col1\" class=\"col_heading level0 col1\" >Model name</th>\n",
       "      <th id=\"T_a8cf4_level0_col2\" class=\"col_heading level0 col2\" >Accuracy</th>\n",
       "      <th id=\"T_a8cf4_level0_col3\" class=\"col_heading level0 col3\" >Precision</th>\n",
       "      <th id=\"T_a8cf4_level0_col4\" class=\"col_heading level0 col4\" >Recall</th>\n",
       "      <th id=\"T_a8cf4_level0_col5\" class=\"col_heading level0 col5\" >F1 Score</th>\n",
       "      <th id=\"T_a8cf4_level0_col6\" class=\"col_heading level0 col6\" >Model type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a8cf4_level0_row0\" class=\"row_heading level0 row0\" >1</th>\n",
       "      <td id=\"T_a8cf4_row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "      <td id=\"T_a8cf4_row0_col1\" class=\"data row0 col1\" >Naive Bayes</td>\n",
       "      <td id=\"T_a8cf4_row0_col2\" class=\"data row0 col2\" >0.94</td>\n",
       "      <td id=\"T_a8cf4_row0_col3\" class=\"data row0 col3\" >0.99</td>\n",
       "      <td id=\"T_a8cf4_row0_col4\" class=\"data row0 col4\" >0.88</td>\n",
       "      <td id=\"T_a8cf4_row0_col5\" class=\"data row0 col5\" >0.93</td>\n",
       "      <td id=\"T_a8cf4_row0_col6\" class=\"data row0 col6\" >Baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a8cf4_level0_row1\" class=\"row_heading level0 row1\" >2</th>\n",
       "      <td id=\"T_a8cf4_row1_col0\" class=\"data row1 col0\" >2</td>\n",
       "      <td id=\"T_a8cf4_row1_col1\" class=\"data row1 col1\" >Logistic Regression</td>\n",
       "      <td id=\"T_a8cf4_row1_col2\" class=\"data row1 col2\" >0.99</td>\n",
       "      <td id=\"T_a8cf4_row1_col3\" class=\"data row1 col3\" >0.99</td>\n",
       "      <td id=\"T_a8cf4_row1_col4\" class=\"data row1 col4\" >0.99</td>\n",
       "      <td id=\"T_a8cf4_row1_col5\" class=\"data row1 col5\" >0.99</td>\n",
       "      <td id=\"T_a8cf4_row1_col6\" class=\"data row1 col6\" >Traditional Machine Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a8cf4_level0_row2\" class=\"row_heading level0 row2\" >3</th>\n",
       "      <td id=\"T_a8cf4_row2_col0\" class=\"data row2 col0\" >3</td>\n",
       "      <td id=\"T_a8cf4_row2_col1\" class=\"data row2 col1\" >CNN</td>\n",
       "      <td id=\"T_a8cf4_row2_col2\" class=\"data row2 col2\" >1.00</td>\n",
       "      <td id=\"T_a8cf4_row2_col3\" class=\"data row2 col3\" >1.00</td>\n",
       "      <td id=\"T_a8cf4_row2_col4\" class=\"data row2 col4\" >1.00</td>\n",
       "      <td id=\"T_a8cf4_row2_col5\" class=\"data row2 col5\" >1.00</td>\n",
       "      <td id=\"T_a8cf4_row2_col6\" class=\"data row2 col6\" >Deep Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a8cf4_level0_row3\" class=\"row_heading level0 row3\" >0</th>\n",
       "      <td id=\"T_a8cf4_row3_col0\" class=\"data row3 col0\" >4</td>\n",
       "      <td id=\"T_a8cf4_row3_col1\" class=\"data row3 col1\" >BERT</td>\n",
       "      <td id=\"T_a8cf4_row3_col2\" class=\"data row3 col2\" >1.00</td>\n",
       "      <td id=\"T_a8cf4_row3_col3\" class=\"data row3 col3\" >0.99</td>\n",
       "      <td id=\"T_a8cf4_row3_col4\" class=\"data row3 col4\" >1.00</td>\n",
       "      <td id=\"T_a8cf4_row3_col5\" class=\"data row3 col5\" >1.00</td>\n",
       "      <td id=\"T_a8cf4_row3_col6\" class=\"data row3 col6\" >Transformer-Based</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a8cf4_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_a8cf4_row4_col0\" class=\"data row4 col0\" >5</td>\n",
       "      <td id=\"T_a8cf4_row4_col1\" class=\"data row4 col1\" >Stacking Ensemble</td>\n",
       "      <td id=\"T_a8cf4_row4_col2\" class=\"data row4 col2\" >1.00</td>\n",
       "      <td id=\"T_a8cf4_row4_col3\" class=\"data row4 col3\" >1.00</td>\n",
       "      <td id=\"T_a8cf4_row4_col4\" class=\"data row4 col4\" >1.00</td>\n",
       "      <td id=\"T_a8cf4_row4_col5\" class=\"data row4 col5\" >1.00</td>\n",
       "      <td id=\"T_a8cf4_row4_col6\" class=\"data row4 col6\" >Meta Classifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7594429d1160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "Test Scores Comparison for All Models - Test 2 Set (Football Domain)\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_38594_row0_col2, #T_38594_row1_col2, #T_38594_row2_col2, #T_38594_row3_col2, #T_38594_row4_col2 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_38594\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_38594_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_38594_level0_col1\" class=\"col_heading level0 col1\" >Model name</th>\n",
       "      <th id=\"T_38594_level0_col2\" class=\"col_heading level0 col2\" >Accuracy</th>\n",
       "      <th id=\"T_38594_level0_col3\" class=\"col_heading level0 col3\" >Precision</th>\n",
       "      <th id=\"T_38594_level0_col4\" class=\"col_heading level0 col4\" >Recall</th>\n",
       "      <th id=\"T_38594_level0_col5\" class=\"col_heading level0 col5\" >F1 Score</th>\n",
       "      <th id=\"T_38594_level0_col6\" class=\"col_heading level0 col6\" >Model type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_38594_level0_row0\" class=\"row_heading level0 row0\" >1</th>\n",
       "      <td id=\"T_38594_row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "      <td id=\"T_38594_row0_col1\" class=\"data row0 col1\" >Naive Bayes</td>\n",
       "      <td id=\"T_38594_row0_col2\" class=\"data row0 col2\" >0.93</td>\n",
       "      <td id=\"T_38594_row0_col3\" class=\"data row0 col3\" >0.93</td>\n",
       "      <td id=\"T_38594_row0_col4\" class=\"data row0 col4\" >0.94</td>\n",
       "      <td id=\"T_38594_row0_col5\" class=\"data row0 col5\" >0.93</td>\n",
       "      <td id=\"T_38594_row0_col6\" class=\"data row0 col6\" >Baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_38594_level0_row1\" class=\"row_heading level0 row1\" >2</th>\n",
       "      <td id=\"T_38594_row1_col0\" class=\"data row1 col0\" >2</td>\n",
       "      <td id=\"T_38594_row1_col1\" class=\"data row1 col1\" >Logistic Regression</td>\n",
       "      <td id=\"T_38594_row1_col2\" class=\"data row1 col2\" >0.95</td>\n",
       "      <td id=\"T_38594_row1_col3\" class=\"data row1 col3\" >0.95</td>\n",
       "      <td id=\"T_38594_row1_col4\" class=\"data row1 col4\" >0.95</td>\n",
       "      <td id=\"T_38594_row1_col5\" class=\"data row1 col5\" >0.95</td>\n",
       "      <td id=\"T_38594_row1_col6\" class=\"data row1 col6\" >Traditional Machine Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_38594_level0_row2\" class=\"row_heading level0 row2\" >3</th>\n",
       "      <td id=\"T_38594_row2_col0\" class=\"data row2 col0\" >3</td>\n",
       "      <td id=\"T_38594_row2_col1\" class=\"data row2 col1\" >CNN</td>\n",
       "      <td id=\"T_38594_row2_col2\" class=\"data row2 col2\" >0.94</td>\n",
       "      <td id=\"T_38594_row2_col3\" class=\"data row2 col3\" >0.96</td>\n",
       "      <td id=\"T_38594_row2_col4\" class=\"data row2 col4\" >0.94</td>\n",
       "      <td id=\"T_38594_row2_col5\" class=\"data row2 col5\" >0.95</td>\n",
       "      <td id=\"T_38594_row2_col6\" class=\"data row2 col6\" >Deep Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_38594_level0_row3\" class=\"row_heading level0 row3\" >0</th>\n",
       "      <td id=\"T_38594_row3_col0\" class=\"data row3 col0\" >4</td>\n",
       "      <td id=\"T_38594_row3_col1\" class=\"data row3 col1\" >BERT</td>\n",
       "      <td id=\"T_38594_row3_col2\" class=\"data row3 col2\" >0.96</td>\n",
       "      <td id=\"T_38594_row3_col3\" class=\"data row3 col3\" >0.94</td>\n",
       "      <td id=\"T_38594_row3_col4\" class=\"data row3 col4\" >0.98</td>\n",
       "      <td id=\"T_38594_row3_col5\" class=\"data row3 col5\" >0.96</td>\n",
       "      <td id=\"T_38594_row3_col6\" class=\"data row3 col6\" >Transformer-Based</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_38594_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_38594_row4_col0\" class=\"data row4 col0\" >5</td>\n",
       "      <td id=\"T_38594_row4_col1\" class=\"data row4 col1\" >Stacking Ensemble</td>\n",
       "      <td id=\"T_38594_row4_col2\" class=\"data row4 col2\" >0.96</td>\n",
       "      <td id=\"T_38594_row4_col3\" class=\"data row4 col3\" >0.97</td>\n",
       "      <td id=\"T_38594_row4_col4\" class=\"data row4 col4\" >0.95</td>\n",
       "      <td id=\"T_38594_row4_col5\" class=\"data row4 col5\" >0.96</td>\n",
       "      <td id=\"T_38594_row4_col6\" class=\"data row4 col6\" >Meta Classifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x759442af31f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------------------------\n",
    "# Load and display all model results on Test 1 and Test 2 sets\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "for i in range(2):\n",
    "    if (i+1 == 1):\n",
    "        domain = 'News'\n",
    "    else:\n",
    "        domain = 'Football'\n",
    "\n",
    "    # Call function - to load and display all model results on Validation set\n",
    "    file_path = f'results/all_model_results_test_{i+1}.pkl'\n",
    "    table_desc = f'Test Scores Comparison for All Models - Test {i+1} Set ({domain} Domain)'\n",
    "    load_and_display_metric_scores(file_path, table_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1ea035-1277-4745-81d6-34c813c5d5b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_cnn_p39",
   "language": "python",
   "name": "tf_env_p39_pip_21mar"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
